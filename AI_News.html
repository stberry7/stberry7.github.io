<!--  20240416 0624 만듬 -->
<!DOCTYPE html>

<html lang="ko">
<head>
<meta charset="utf-8"/>
<title>
    인공지능 뉴스 (AI News)
  </title>
<style>
   body {
            font-family: Arial, sans-serif;
        }

        header {
            background-color: #f8f9fa;
            padding: 20px;
            text-align: center;
        }

        main {
            margin: 2rem auto;
            max-width: 1200px;
            padding: 0 1rem;
            background-color: #fff;
            box-shadow: 0 0 10px rgba(0, 0, 0, 0.1);
            border-radius: 5px;
            padding: 2rem;
            font-size: 24px;
        }

        ul {
            list-style-type: none;
            padding: 0;
        }

        li {
            margin-bottom: 10px;
            padding: 10px;
            border: 1px solid #ddd;
            border-radius: 4px;
        }

        footer {
            background-color: #f8f9fa;
            padding: 20px;
            text-align: center;
            /* position: fixed; */
            position: center;
            width: 100%;
            bottom: 0;
        }
  </style>
<style>
   .home-button {
    display: inline-block;
    padding: 20px 100px;
    font-size: 64px;
    color: white;
    background-color: blue;
    border: none;
    border-radius: 5px;
    text-decoration: none;
    transition: background-color 0.3s ease;
}

.home-button:hover {
    background-color: darkblue;
}
  </style>
<style>
   .circle {
    position: absolute;
    height: 100px;
    width: 100px;
    border-radius: 50%;
    border: 5px solid;
    animation: circleFadeOut 1s forwards;
}

@keyframes circleFadeOut {
    from {transform: scale(0.5); opacity: 1;}
    to {transform: scale(1.5); opacity: 0;}
}
  </style>
<style>
   .message {
    position: absolute;
    font-size: 20px;
    color: red;
    animation: messageFadeOut 1s forwards;
}

@keyframes messageFadeOut {
    from {opacity: 1;}
    to {opacity: 0;}
}
  </style>
</head>

<header>
<a class="home-button" href="index.html">
    Home
   </a>
<h1>
    인공지능 뉴스
   </h1>
<p>
    인공지능 뉴스 웹페이지입니다.
    
   </p>
</header>
<main>

<h2>
    인공지능 뉴스
    </h2>


    <ul>
        <li>
        <p>
        <strong>
                </strong>
                중국 최대 정보기술(IT) 기업인 텐센트가 개발한 인공지능(AI) 대규모언어모델(LLM) '훈위안'이 최근 학습한 토큰(말뭉치) 수가 3조 개에 달한다는 사실이 알려졌다. 이는 지난해 9월 훈위안 첫 공개 당시 밝힌 2조 개에서 불과 7개월 만에 50%나 증가한 수치다. 이는 네이버가 2021년 선보인 한국 최초 LLM의 5600억 토큰과 비교해도 압도적인 규모로, '챗GPT의 아버지'로 불리는 샘 올트먼의 오픈AI가 2020년 GPT3 출범 당시 투입한 3000억 개 토큰과 비교해도 훨씬 빠른 속도다. 텐센트의 이러한 빠른 추격에 세계 빅테크들이 경계심을 갖는 이유다.<br>
                텐센트가 AI 개발에 본격적으로 뛰어든 것은 2016년으로 거슬러 올라간다. 당시 텐센트는 텐센트AI랩을 설립하고, 자사의 SNS인 위챗과 웨이신을 통해 축적한 방대한 데이터를 AI 학습에 활용하기 시작했다. 지난 18일 방문한 중국 광저우 위챗·웨이신 사무동에 따르면, 현재 이 두 SNS의 이용자 수는 14억 4700만 명에 달한다. 이 중 중국인 이용자가 13억 5900만 명으로 거의 모든 중국인이 사용하고 있으며, 외국인 이용자도 1억 명에 육박한다. 텐센트 관계자는 "대다수 AI 기업이 토큰에 쓸 데이터 부족으로 어려움을 겪고 있지만, 텐센트는 걱정할 필요가 없다"고 말했다. 위챗이 금융 거래부터 진료 예약, 처방전 발송, 식당 결제, 택시 콜, 공유자전거 이용 등 일상생활 전반에 활용되는 '생활 리모컨' 역할을 하기 때문에 AI 학습에 필요한 토큰을 대량으로 확보할 수 있기 때문이다.<br>
                AI 성능 개선에 있어 토큰은 가장 확실한 수단으로 꼽힌다. 아무리 최첨단 AI 칩을 사용한다 해도 학습에 투입되는 데이터가 부족하다면 성능 향상에 한계가 있기 마련이다. 반면 칩의 성능이 다소 떨어지더라도 방대한 데이터를 학습한다면 더 나은 결과를 기대할 수 있다. 네이버 관계자는 "오프라인의 실시간 데이터를 대규모로 확보하는 곳은 중국 빅테크뿐"이라고 말했다.<br>
                텐센트의 마화텅 회장은 훈위안을 고도화하는 한편, 기업AI로 사업 영역을 확장하고 있다. 그는 최근 임직원에게 보낸 메시지에서 "훈위안은 수치 추론, 논리적 추론, 다단계 대화 등에서 탁월한 성능을 발휘하는 최상위 모델"이라고 강조했다. 훈위안은 이미지 생성, 텍스트 인식, 카피라이팅 등 다양한 기능을 지원하며, SNS, 금융, 공공 서비스, 전자상거래, 물류 운송, 게임 등 주요 산업에서 활용도가 높다. 다우슨 퉁 텐센트 수석부사장은 "금융, 교육, 물류, 게임 등 20개 산업군에 걸쳐 50여 개 솔루션을 보유한 기업용 훈위안 서비스를 중국 기업에 제공하고 있다"며 "각 기업에 최적화된 지능형 서비스를 선보일 것"이라고 말했다.<br>
                기업AI는 그동안 중국의 최대 약점으로 꼽혀왔다. 소비 영역과 달리 중국 기업이 자체적으로 축적한 '정형화된 데이터'가 부족했기 때문이다. 텐센트는 자사의 AI 클라우드를 통해 주요 산업의 데이터를 끌어모음으로써 이러한 약점을 극복하겠다는 계획이다. 구글, 아마존, 마이크로소프트 등이 주도하는 초거대 AI 생태계와는 완전히 다른, 별개의 'AI 행성'을 만들겠다는 것이 마화텅 회장의 전략이다. 실제로 텐센트는 지난달 자체 개발한 생성형 AI 게임엔진 '지넥스'를 공개하며 이에 대한 의지를 내비쳤다. 생성형 AI를 활용해 콘텐츠 제작 시간을 단축하고 풍성한 게임 스토리를 만들어낼 수 있는 혁신적인 도구인 셈이다. 텐센트는 현재 훈위안의 기업AI를 자사의 사업 및 서비스에 적용 중인데, 그 분야만 해도 400개에 달한다고 한다.<br>
                텐센트는 AI 기술을 바탕으로 글로벌 시장 공략에도 적극적으로 나서고 있다. 2016년 아시아, 유럽, 미국을 아우르는 글로벌 파트너 네트워크를 구축한 것을 시작으로 해외 진출을 본격화했으며, 최근에는 중남미와 중동 지역에서 독자적인 생태계를 구축하는 중이다. 자오젠난 텐센트 클라우드인터내셔널 부사장은 "클라우드, AI, 빅데이터, 보안 등 주요 기술을 통합해 맞춤형 디지털 솔루션을 구축해주는 형태의 글로벌 사업을 키워나갈 것"이라고 밝혔다. 이를 위해 텐센트는 지난해에만 640억 위안(약 12조 원)을 연구개발(R&D)에 투자했는데, 이는 역대 최대 규모다. 올해는 R&D 투자금 중 AI 관련 비중을 더욱 높일 것으로 알려졌다.<br>
                중국 IT 공룡 텐센트의 야심찬 행보가 주목되는 이유다. 자국 내 시장에서의 독보적인 지위를 바탕으로 축적한 데이터와 AI 기술력을 앞세워 글로벌 무대에서도 존재감을 과시하겠다는 전략이 엿보인다. 구글, 아마존, 마이크로소프트 등 미국 빅테크 기업들이 주도하는 AI 시장에서 새로운 강자로 부상할 수 있을지 귀추가 주목된다. 다만 중국 정부의 규제와 검열, 데이터 보안 문제 등은 여전히 텐센트가 넘어야 할 과제로 남아있다. 글로벌 시장에서 통할 수 있는 보편적인 가치와 기준을 충족시키는 것도 중요한 숙제다. 텐센트의 행보가 중국 IT 기업의 새로운 가능성을 보여줄 수 있을지, 아니면 자국 시장에 갇힌 한계를 노출할 지 지켜볼 일이다.<br><br>
                <a href="https://www.hankyung.com/article/2024042159721" target="_blank"> 2024년04월21일 : 한국경제 '토큰 3조개' 익힌 텐센트 AI, 챗GPT보다 학습속도 빨라  </a> <br>  
        </p>

        </li>
        <!-- 이곳에 더 많은 표현을 추가할 수 있습니다 -->
        </ul>

    <ul>
        <li>
        <p>
        <strong>
                </strong>
                최근 기업들이 인공지능(AI)을 활용한 코딩 및 개발에 투자를 집중하면서, 정보기술(IT) 개발자들의 입지가 흔들리고 있습니다. AI가 중급 이상의 코딩을 수행할 수 있게 되어, 기업들은 고연봉 IT 개발자 대신 비용 효율적인 AI에 투자하는 추세입니다.
                해외 빅테크 기업들은 대규모 구조조정을 통해 절감된 비용을 AI 개발에 투자하고 있으며, 전문가들은 AI가 IT 개발자의 직무를 대체할 수 있을 것으로 전망합니다. 국내에서도 AI로 인한 일자리 대체 우려가 확산되고 있으며, IT 개발자 채용이 감소하는 추세입니다.
                국내 대형 IT 기업들은 연봉 및 인센티브 인상률을 낮추고 AI에 자금을 집중하고 있습니다. 네이버와 카카오의 직원 평균 연봉도 감소했으며, 이는 AI 투자를 늘리기 위한 조치로 보입니다.
                전문가들은 기업들이 AI의 효율성을 확인하게 되면, 뛰어난 인재를 제외하고는 새로운 개발자 채용을 줄일 가능성이 높다고 예측합니다. AI의 발전이 IT 개발자의 일자리에 상당한 영향을 미칠 것으로 보입니다.<br><br>
                <a href="https://m.mk.co.kr/amp/10992831" target="_blank"> 2024년04월17일 : 매일경제 “억대 연봉 옛말 됐다”…이 직원 4명분 AI가 도맡아 ‘대규모 칼바람’  </a> <br>  
        </p>

        </li>
        <!-- 이곳에 더 많은 표현을 추가할 수 있습니다 -->
        </ul>

        <ul>
        <li>
        <p>
        <strong>
                </strong>
                2024년 가장 많이 사용되는 인공지능(AI) 플랫폼 20개를 선정한 결과는 다음과 같습니다:                 오픈AI의 '챗GPT'가 방문수 16억1000만건으로 1위                구글의 '제미나이'가 3억9120만건으로 2위                번역 AI인 '딥엘(DeepL)'이 2억4130만건으로 3위
                캐릭터닷AI의 챗봇                퍼플렉시티 AI의 AI 기반 검색엔진                앤트로픽의 '클로드'                쿼라의 AI 챗봇 '포'                마이크로소프트(MS)의 '코파일럿'                AI 언어모델인 '다이얼로GPT'                AI 기반 검색엔진 '유챗'
                11~20위는 '오터', '소크라틱', '힉스.AI', '라이트소닉', '카피AI', '재스퍼', '엘사', 깃허브의 '코파일럿', '코디엄', '탭나인' 등이 차지했습니다.                이 순위는 미국 투자 전문매체 인사이더몽키가 인터넷 상의 10개 이상의 순위 사이트 중 50% 이상 등장한 플랫폼들을 선택하고, 지난 28일간의 총 사이트 방문수를 기준으로 선정한 것입니다. 웹사이트가 없는 플랫폼은 총 구독자 수나 사용자 수를 기준으로 순위를 매겼습니다.<br><br>
                <a href="https://www.aitimes.com/news/articleView.html?idxno=158780" target="_blank">2024년04월14일 : AI Times 2024년 가장 많이 사용되는 AI 플랫폼 20개는 </a> <br>
        </p>

        </li>
        <!-- 이곳에 더 많은 표현을 추가할 수 있습니다 -->
        </ul>

        <ul>
            <li>
            <p>
            <strong>
                    </strong>
                    최근 챗GPT 유료 사용자들 사이에서 GPT-4의 게으름 문제가 다시 불거졌습니다. 이는 챗봇이 응답을 거부하는 등 정상적으로 작동하지 않는 것을 말합니다. 이 문제는 작년 여름부터 반복되어 왔고, 오픈AI는 GPT-4 터보 출시 등으로 대응했지만 근본적인 해결책을 내놓지 못했습니다.
                    이에 따라 일부 사용자들은 앤트로픽의 최신 모델인 '클로드 3'로 갈아타고 있습니다. 클로드 3는 벤치마크 결과와 사용자 선호도 평가에서 GPT-4를 능가하는 성능을 보이고 있습니다.
                    전문가들은 오픈AI가 다음 모델 개발에 집중하고 있어 이 문제에 적극적으로 대처하지 않을 것이라고 우려하고 있습니다. 오픈AI는 올여름 GPT-5를 출시할 예정이며, 게으름 문제에 대한 논평은 거부했습니다.<br><br>
                    <a href="https://www.aitimes.com/news/articleView.html?idxno=158387" target="_blank">2024년03월29일 : AI Times "GPT-4 다시 게을러져...클로드 3로 갈아타자" 여론 확산 </a> <br>
            </p>
    
            </li>
            <!-- 이곳에 더 많은 표현을 추가할 수 있습니다 -->
            </ul>

            <ul>
                <li>
                <p>
                <strong>
                        </strong>
                        구글이 트랜스포머 아키텍처의 약점을 보완하기 위해 '인피니-어텐션'과 '리커런트젬마'라는 두 가지 기술을 공개했다.
                        인피니-어텐션은 LLM(대형언어모델)의 컨텍스트 창 길이를 무한 확장할 수 있는 기술이다. 일반적인 어텐션 메커니즘에 '압축 메모리'를 통합하여, 입력이 컨텍스트 길이를 초과하면 이전 어텐션 상태를 압축 메모리에 저장한다. 이를 통해 메모리 추가 없이도 100만 개 이상의 토큰 품질을 유지할 수 있다. 인피니-어텐션을 적용하면 모든 문서를 프롬프트에 삽입하고 관련성 높은 답변을 선택할 수 있으며, 긴 예제를 제공해 모델을 사용자 정의할 수 있다.
                        리커런트젠마는 엣지 장치용 오픈 소스 소형언어모델로, 트랜스포머 기반 모델처럼 모든 정보를 병렬로 처리하는 대신 '로컬 어텐션 메커니즘'을 도입하여 주어진 시간에 입력 데이터에 집중하여 처리한다. 이를 통해 성능은 유지하면서 계산 부하를 줄이고 처리 속도를 높였다. 리소스가 제한된 엣지 장치에 배포하기 적합하며, 실시간 엣지 애플리케이션에 적합하다. 순환 신경망(RNN)의 기본 구성 요소인 선형 반복을 어텐션과 결합하여, 입력 데이터에 관계없이 일정한 수준의 리소스 사용량을 유지하면서 확장된 텍스트를 처리할 수 있다.
                        이러한 기술들은 트랜스포머 아키텍처의 약점을 극복하고, LLM의 활용 범위를 확대할 수 있을 것으로 기대된다.<br><br>
                        <a href="https://www.aitimes.com/news/articleView.html?idxno=158799" target="_blank">2024년03월14일 : AI Times 구글, '트랜스포머' 보완할 기술 잇달아 공개…”메모리·시간 축소” </a> <br><br>
                </p>
        
                </li>
                <!-- 이곳에 더 많은 표현을 추가할 수 있습니다 -->
                </ul>



</main>


<footer>
   © 2023~2024 AI NEWS. All rights reserved.
   <a href="mailto:stberry7@gmail.com?subject=Hello&amp;body=Nice%20to%20meet%20you">
    Email me
   </a>
</footer>
<script>
   var clickCount = 0;
  </script>
<style>
.firework {
    position: absolute;
    width: 1px;
    height: 1px;
    border-radius: 50%;
    background: red;
    animation: explode 3s ease-out;
}

@keyframes explode {
    to {
        transform: scale(30);
        opacity: 0;
    }
}
</style>
<script>
var colors = ['#ffb3ba', '#ffdfba', '#ffffba', '#baffc9', '#bae1ff'];

document.addEventListener('click', function(event) {
    if (event.clientX < 30 || event.clientX > window.innerWidth - 30 ||
        event.clientY < 30 || event.clientY > window.innerHeight - 30) {
        return;
    }
    for (var i = 0; i < 10; i++) {
        var firework = document.createElement('div');
        firework.className = 'firework';
        // firework.style.top = (event.clientY - 0.5) + 'px';
        firework.style.top = (event.clientY+ window.scrollY - 0.5) + 'px';
        firework.style.left = (event.clientX - 0.5) + 'px';
        // firework.style.top = (event.clientY + window.scrollY - 0.5) + 'px'; // Adjusted for scroll
        firework.style.backgroundColor = colors[Math.floor(Math.random() * colors.length)];
        firework.style.transform = 'translate(' + (Math.random() * 200 - 100) + 'px, ' + (Math.random() * 200 - 100) + 'px)';
        document.body.appendChild(firework);
        setTimeout(function() {
            document.body.removeChild(firework);
        }, 3000);
    }
});
</script>
</body>
</html>
