<!--  20240416 0624 만듬 -->
<!DOCTYPE html>

<html lang="ko">
<head>
<meta charset="utf-8"/>
<title>
    인공지능 뉴스 (AI News)
  </title>
<style>
   body {
            font-family: Arial, sans-serif;
        }

        header {
            background-color: #f8f9fa;
            padding: 20px;
            text-align: center;
        }

        main {
            margin: 2rem auto;
            max-width: 1200px;
            padding: 0 1rem;
            background-color: #fff;
            box-shadow: 0 0 10px rgba(0, 0, 0, 0.1);
            border-radius: 5px;
            padding: 2rem;
            font-size: 24px;
        }
            @media screen and (max-width: 768px) {
            main {
                font-size: 120px;
            }
        }
        ul {
            list-style-type: none;
            padding: 0;
        }

        li {
            margin-bottom: 10px;
            padding: 10px;
            border: 1px solid #ddd;
            border-radius: 4px;
        }

        footer {
            background-color: #f8f9fa;
            padding: 20px;
            text-align: center;
            /* position: fixed; */
            position: center;
            width: 100%;
            bottom: 0;
        }
  </style>
<style>
   .home-button {
    display: inline-block;
    padding: 20px 100px;
    font-size: 64px;
    color: white;
    background-color: blue;
    border: none;
    border-radius: 5px;
    text-decoration: none;
    transition: background-color 0.3s ease;
}

.home-button:hover {
    background-color: darkblue;
}
  </style>
<style>
   .circle {
    position: absolute;
    height: 100px;
    width: 100px;
    border-radius: 50%;
    border: 5px solid;
    animation: circleFadeOut 1s forwards;
}

@keyframes circleFadeOut {
    from {transform: scale(0.5); opacity: 1;}
    to {transform: scale(1.5); opacity: 0;}
}
  </style>
<style>
   .message {
    position: absolute;
    font-size: 20px;
    color: red;
    animation: messageFadeOut 1s forwards;
}

@keyframes messageFadeOut {
    from {opacity: 1;}
    to {opacity: 0;}
}
  </style>
</head>

<header>
<a class="home-button" href="index.html">
    Home
   </a>
<h1>
    인공지능 뉴스
   </h1>
<p>
    인공지능 뉴스 웹페이지입니다.
    
   </p>
</header>
<main>

<h2>
    인공지능 뉴스
    </h2>


    <ul>
        <li>
        <p>
        <strong>
                </strong>
                중국 최대 정보기술(IT) 기업인 텐센트가 개발한 인공지능(AI) 대규모언어모델(LLM) '훈위안'이 최근 학습한 토큰(말뭉치) 수가 3조 개에 달한다는 사실이 알려졌다. 이는 지난해 9월 훈위안 첫 공개 당시 밝힌 2조 개에서 불과 7개월 만에 50%나 증가한 수치다. 이는 네이버가 2021년 선보인 한국 최초 LLM의 5600억 토큰과 비교해도 압도적인 규모로, '챗GPT의 아버지'로 불리는 샘 올트먼의 오픈AI가 2020년 GPT3 출범 당시 투입한 3000억 개 토큰과 비교해도 훨씬 빠른 속도다. 텐센트의 이러한 빠른 추격에 세계 빅테크들이 경계심을 갖는 이유다.<br><br>
                텐센트가 AI 개발에 본격적으로 뛰어든 것은 2016년으로 거슬러 올라간다. 당시 텐센트는 텐센트AI랩을 설립하고, 자사의 SNS인 위챗과 웨이신을 통해 축적한 방대한 데이터를 AI 학습에 활용하기 시작했다. 지난 18일 방문한 중국 광저우 위챗·웨이신 사무동에 따르면, 현재 이 두 SNS의 이용자 수는 14억 4700만 명에 달한다. 이 중 중국인 이용자가 13억 5900만 명으로 거의 모든 중국인이 사용하고 있으며, 외국인 이용자도 1억 명에 육박한다. 텐센트 관계자는 "대다수 AI 기업이 토큰에 쓸 데이터 부족으로 어려움을 겪고 있지만, 텐센트는 걱정할 필요가 없다"고 말했다. 위챗이 금융 거래부터 진료 예약, 처방전 발송, 식당 결제, 택시 콜, 공유자전거 이용 등 일상생활 전반에 활용되는 '생활 리모컨' 역할을 하기 때문에 AI 학습에 필요한 토큰을 대량으로 확보할 수 있기 때문이다.<br><br>
                AI 성능 개선에 있어 토큰은 가장 확실한 수단으로 꼽힌다. 아무리 최첨단 AI 칩을 사용한다 해도 학습에 투입되는 데이터가 부족하다면 성능 향상에 한계가 있기 마련이다. 반면 칩의 성능이 다소 떨어지더라도 방대한 데이터를 학습한다면 더 나은 결과를 기대할 수 있다. 네이버 관계자는 "오프라인의 실시간 데이터를 대규모로 확보하는 곳은 중국 빅테크뿐"이라고 말했다.<br><br>
                텐센트의 마화텅 회장은 훈위안을 고도화하는 한편, 기업AI로 사업 영역을 확장하고 있다. 그는 최근 임직원에게 보낸 메시지에서 "훈위안은 수치 추론, 논리적 추론, 다단계 대화 등에서 탁월한 성능을 발휘하는 최상위 모델"이라고 강조했다. 훈위안은 이미지 생성, 텍스트 인식, 카피라이팅 등 다양한 기능을 지원하며, SNS, 금융, 공공 서비스, 전자상거래, 물류 운송, 게임 등 주요 산업에서 활용도가 높다. 다우슨 퉁 텐센트 수석부사장은 "금융, 교육, 물류, 게임 등 20개 산업군에 걸쳐 50여 개 솔루션을 보유한 기업용 훈위안 서비스를 중국 기업에 제공하고 있다"며 "각 기업에 최적화된 지능형 서비스를 선보일 것"이라고 말했다.<br><br>
                기업AI는 그동안 중국의 최대 약점으로 꼽혀왔다. 소비 영역과 달리 중국 기업이 자체적으로 축적한 '정형화된 데이터'가 부족했기 때문이다. 텐센트는 자사의 AI 클라우드를 통해 주요 산업의 데이터를 끌어모음으로써 이러한 약점을 극복하겠다는 계획이다. 구글, 아마존, 마이크로소프트 등이 주도하는 초거대 AI 생태계와는 완전히 다른, 별개의 'AI 행성'을 만들겠다는 것이 마화텅 회장의 전략이다. 실제로 텐센트는 지난달 자체 개발한 생성형 AI 게임엔진 '지넥스'를 공개하며 이에 대한 의지를 내비쳤다. 생성형 AI를 활용해 콘텐츠 제작 시간을 단축하고 풍성한 게임 스토리를 만들어낼 수 있는 혁신적인 도구인 셈이다. 텐센트는 현재 훈위안의 기업AI를 자사의 사업 및 서비스에 적용 중인데, 그 분야만 해도 400개에 달한다고 한다.<br><br>
                텐센트는 AI 기술을 바탕으로 글로벌 시장 공략에도 적극적으로 나서고 있다. 2016년 아시아, 유럽, 미국을 아우르는 글로벌 파트너 네트워크를 구축한 것을 시작으로 해외 진출을 본격화했으며, 최근에는 중남미와 중동 지역에서 독자적인 생태계를 구축하는 중이다. 자오젠난 텐센트 클라우드인터내셔널 부사장은 "클라우드, AI, 빅데이터, 보안 등 주요 기술을 통합해 맞춤형 디지털 솔루션을 구축해주는 형태의 글로벌 사업을 키워나갈 것"이라고 밝혔다. 이를 위해 텐센트는 지난해에만 640억 위안(약 12조 원)을 연구개발(R&D)에 투자했는데, 이는 역대 최대 규모다. 올해는 R&D 투자금 중 AI 관련 비중을 더욱 높일 것으로 알려졌다.<br><br>
                중국 IT 공룡 텐센트의 야심찬 행보가 주목되는 이유다. 자국 내 시장에서의 독보적인 지위를 바탕으로 축적한 데이터와 AI 기술력을 앞세워 글로벌 무대에서도 존재감을 과시하겠다는 전략이 엿보인다. 구글, 아마존, 마이크로소프트 등 미국 빅테크 기업들이 주도하는 AI 시장에서 새로운 강자로 부상할 수 있을지 귀추가 주목된다. 다만 중국 정부의 규제와 검열, 데이터 보안 문제 등은 여전히 텐센트가 넘어야 할 과제로 남아있다. 글로벌 시장에서 통할 수 있는 보편적인 가치와 기준을 충족시키는 것도 중요한 숙제다. 텐센트의 행보가 중국 IT 기업의 새로운 가능성을 보여줄 수 있을지, 아니면 자국 시장에 갇힌 한계를 노출할 지 지켜볼 일이다.<br><br>
                <a href="https://www.hankyung.com/article/2024042159721" target="_blank"> 2024년04월21일 : 한국경제 '토큰 3조개' 익힌 텐센트 AI, 챗GPT보다 학습속도 빨라  </a> <br>  
        </p>

        </li>
        <!-- 이곳에 더 많은 표현을 추가할 수 있습니다 -->
        </ul>

    <ul>
        <li>
        <p>
        <strong>
                </strong>
                인공지능(AI)이 IT 개발자들의 핵심 업무인 코딩을 중급 이상으로 수행할 수 있게 되면서, 기업들은 고연봉 IT 개발자 대신 비용 효율적인 AI에 투자하는 추세로 바뀌고 있습니다. 이로 인해 IT 개발자들의 입지가 흔들리고 있는 상황입니다.<br><br>
                최근 전 세계 기업들은 IT 인재 영입에 들일 자금을 자체 AI 개발에 투자하고 있습니다. 구글, 마이크로소프트, 아마존 등 해외 빅테크 기업들은 대규모 구조조정을 단행하고, 절감된 비용을 AI 개발에 투자하고 있습니다. 구글은 370억 달러(약 51조 원)를, 마이크로소프트는 25억 파운드(약 4조 원)를, 아마존은 40억 달러(약 5조 원)와 1억 달러(약 1,385억 원)를 각각 AI 관련 분야에 투자할 계획입니다.<br><br>
                전문가들은 AI가 머지않아 IT 개발자의 직무를 대체할 수 있을 것으로 전망하고 있습니다. 엔비디아 CEO 젠슨 황은 AI의 발전으로 코딩 전문 직업이 사라질 수 있다고 언급했으며, 서울여대 김명주 교수는 AI를 코딩에 적용하면 효율성이 30~40% 향상될 수 있다고 설명했습니다. 아크 인베스트는 AI가 코딩 생산성을 10배 높일 수 있다고 관측했습니다.<br><br>
                국내에서도 AI로 인한 IT 개발자 일자리 대체 우려가 확산되고 있습니다. 원티드랩의 설문조사 결과, 응답자의 83.6%가 AI가 개발자 업무를 대체할 것이라고 답했습니다. 실제로 국내 IT 개발자 채용은 감소 추세를 보이고 있으며, 사람인의 분석에 따르면 지난해 IT 개발·데이터 직무 공고가 전년 대비 7.4% 감소했습니다.<br><br>
                국내 대형 IT 기업들도 연봉 및 인센티브 인상률을 낮추고, AI에 투자를 집중하고 있습니다. 네이버와 카카오의 직원 평균 연봉은 각각 11.5%, 27.3% 감소했으며, 이는 AI 투자를 늘리기 위한 조치로 보입니다.<br><br>
                전문가들은 기업들이 AI의 효율성을 확인하게 되면, 뛰어난 인재를 제외하고는 새로운 개발자 채용을 줄일 가능성이 높다고 예측합니다. AI의 발전이 IT 개발자의 일자리에 상당한 영향을 미칠 것으로 보이며, 이에 따른 고용 구조의 변화가 예상됩니다.<br><br>
                IT 업계에서는 신입 개발자 채용을 지양하고, 검증된 경력자 위주로 선발하는 추세입니다. 프로젝트성 수시 채용만 운영하는 등 채용 규모 자체를 줄이고 있는 상황입니다.<br><br>
                AI의 발전과 기업들의 투자 전략 변화로 인해, IT 개발자들의 고용 환경이 급변하고 있습니다. 단순 코딩 업무는 AI로 대체되고, 개발자들은 AI를 활용하고 관리하는 역할로 전환될 것으로 보입니다. 이러한 변화에 대응하기 위해서는 개발자들의 역량 강화와 함께, 기업과 정부 차원의 고용 안정 대책 마련이 필요할 것으로 사료됩니다.<br><br>
                <a href="https://m.mk.co.kr/amp/10992831" target="_blank"> 2024년04월17일 : 매일경제 “억대 연봉 옛말 됐다”…이 직원 4명분 AI가 도맡아 ‘대규모 칼바람’  </a> <br>  
        </p>

        </li>
        <!-- 이곳에 더 많은 표현을 추가할 수 있습니다 -->
        </ul>

        <ul>
        <li>
        <p>
        <strong>
                </strong>
                2024년 가장 많이 사용되는 인공지능(AI) 플랫폼 순위가 발표되었습니다. 미국 투자 전문매체 인사이더몽키가 인터넷 상의 10개 이상 순위 사이트를 참고하여, 50% 이상 등장한 플랫폼을 선정하고 지난 28일간의 총 사이트 방문수를 기준으로 순위를 매겼습니다. 웹사이트가 없는 플랫폼의 경우에는 총 구독자 수나 사용자 수를 기준으로 하였습니다.<br><br>
                1위는 오픈AI의 챗GPT가 차지했습니다. 방문수 16억 1,000만 건으로 압도적인 성적을 기록했습니다. 2위는 구글의 제미나이가 3억 9,120만 건으로 뒤를 이었고, 3위는 의외로 번역 AI인 딥엘(DeepL)이 2억 4,130만 건으로 차지했습니다.<br><br>
                4위부터 10위까지는 캐릭터닷AI의 챗봇, 퍼플렉시티 AI의 AI 기반 검색엔진, 앤트로픽의 클로드, 쿼라의 AI 챗봇 포, 마이크로소프트(MS)의 코파일럿, AI 언어모델인 다이얼로GPT, AI 기반 검색엔진 유챗이 각각 자리를 잡았습니다.<br><br>
                톱10 중에서 대형언어모델(LLM)이나 AI 챗봇을 기반으로 하지 않은 플랫폼은 번역 AI인 딥엘이 유일했습니다. MS가 8위에 오른 것은 예상 밖의 결과였으며, 퍼플렉시티 AI와 유챗 등 AI 기반 검색 엔진의 상승세도 주목할 만한 점이었습니다.<br><br>
                11위부터 20위까지는 AI 기반 회의 도우미 오터(Otter), 학생들의 숙제 도우미 소크라틱, 글쓰기 지원 AI 힉스.AI, 라이트소닉, 카피AI, AI 챗봇 재스퍼, 영어 음성 도우미 엘사, 코딩 도우미 깃허브의 코파일럿, 코디엄, 탭나인 등이 차지했습니다.<br><br>
                이번 순위는 AI 플랫폼의 대중적 인기와 사용 현황을 잘 보여주고 있습니다. 챗GPT와 같은 대화형 AI 모델의 폭발적인 인기가 두드러지는 가운데, 번역, 검색, 회의, 학습, 글쓰기, 코딩 등 다양한 분야에서 AI 기술이 적용되고 있음을 알 수 있습니다.<br><br>
                특히 대형 IT 기업들의 AI 플랫폼뿐만 아니라, 스타트업과 특화된 AI 서비스들도 상위권에 포진해 있어, AI 산업의 다양성과 경쟁 구도를 엿볼 수 있습니다. 퍼플렉시티 AI나 유챗 등 신생 AI 검색엔진의 약진도 눈에 띕니다.<br><br>
                AI 기술의 발전과 대중화가 가속화되면서, 이러한 AI 플랫폼들은 우리의 일상과 업무 방식에 점점 더 큰 영향을 미칠 것으로 보입니다. 동시에 AI 윤리, 프라이버시, 일자리 등 사회적 이슈에 대한 논의도 더욱 중요해질 전망입니다.<br><br>
                2024년 AI 플랫폼 순위는 급변하는 AI 기술 생태계의 현주소를 보여주는 동시에, 앞으로의 발전 방향을 가늠해볼 수 있는 흥미로운 자료라 할 수 있겠습니다. AI 기술이 가져올 변화와 기회, 그리고 우리 사회가 준비해야 할 과제들을 생각해 볼 수 있는 계기가 될 것 같습니다. <br><br>
                <a href="https://www.aitimes.com/news/articleView.html?idxno=158780" target="_blank">2024년04월14일 : AI Times 2024년 가장 많이 사용되는 AI 플랫폼 20개는 </a> <br>
        </p>

        </li>
        <!-- 이곳에 더 많은 표현을 추가할 수 있습니다 -->
        </ul>

        <ul>
            <li>
            <p>
            <strong>
                    </strong>
                    오픈AI의 챗봇 GPT-4에서 '게으름(laziness)' 문제가 다시 불거지면서, 사용자들 사이에서는 앤트로픽의 경쟁 모델인 '클로드 3'로 갈아타자는 여론이 확산되고 있습니다.
                    GPT-4의 게으름 문제는 챗봇이 응답을 거부하거나 정상적으로 작동하지 않는 현상을 의미합니다. 이 문제는 지난해 여름부터 발생했으며, 당시에는 모델 분할 과정인 '전문가 모델(MoE)' 방식 적용으로 인한 일시적 성능 저하로 여겨졌습니다. 그러나 문제가 반복되자 오픈AI는 작년 11월 GPT-4 터보를 출시하여 해결을 시도했습니다.<br><br>
                    올해 초에도 유사한 문제가 발생했고, 샘 알트먼 오픈AI CEO가 트위터를 통해 이를 인정하고 수정했다고 밝혔지만, 최근 다시 문제가 불거졌습니다. 사용자들은 개발자 포럼과 SNS 등을 통해 모델의 성능 저하와 불완전한 코드 생성 등에 대한 불만을 토로하고 있습니다.<br><br>
                    과거에는 사용자들이 이를 그대로 감수해야 했지만, 이제는 앤트로픽의 '클로드 3'라는 대안이 등장했습니다. 클로드 3는 벤치마크 결과와 인간 선호도 평가에서 GPT-4를 능가하는 성능을 보여주고 있습니다. 엔젤 투자자 앨리 밀러는 대부분의 사람들이 클로드 3를 사용하고 있다고 언급했으며, 이던 몰릭 와튼대학교 교수는 구체적인 사례를 들어 클로드 3의 우수성을 강조했습니다.<br><br>
                    오픈AI가 이 문제에 적절히 대응할 수 있을지에 대해서도 의문이 제기되고 있습니다. 밀러는 오픈AI가 다음 모델 개발에 초점을 맞추고 있어 이 문제에 충분한 자원을 투입하지 않을 것으로 예상했습니다. 실제로 최근 보도에 따르면 오픈AI는 올 여름 GPT-5 출시를 계획하고 있습니다.<br><br>
                    이번 사태는 AI 챗봇 시장에서 경쟁이 심화되고 있음을 보여줍니다. GPT-4의 게으름 문제가 지속될 경우, 사용자들의 이탈이 가속화되고 클로드 3와 같은 경쟁 모델의 점유율이 확대될 가능성이 있습니다. 오픈AI가 이 문제를 신속하고 효과적으로 해결하지 않는다면, 시장에서의 위상이 흔들릴 수 있다는 우려도 제기됩니다.<br><br>
                    한편, 이번 사례는 AI 기술의 발전과 상용화 과정에서 발생할 수 있는 다양한 기술적, 사회적 이슈를 보여주고 있습니다. 챗봇의 성능과 안정성, 사용자 경험, 기업의 대응 능력 등이 중요한 화두로 떠오르고 있으며, 이는 향후 AI 산업의 발전 방향과 속도에 영향을 미칠 것으로 보입니다. AI 기술을 둘러싼 경쟁과 혁신이 가속화되는 가운데, 사용자들의 요구와 기대에 부응하는 서비스를 제공하는 것이 기업들의 핵심 과제로 부상하고 있습니다.<br><br>
                    <a href="https://www.aitimes.com/news/articleView.html?idxno=158387" target="_blank">2024년03월29일 : AI Times "GPT-4 다시 게을러져...클로드 3로 갈아타자" 여론 확산 </a> <br>
            </p>
    
            </li>
            <!-- 이곳에 더 많은 표현을 추가할 수 있습니다 -->
            </ul>

            <ul>
                <li>
                <p>
                <strong>
                        </strong>
                        구글이 입력 데이터가 커질수록 추론 속도가 느려지고 많은 메모리 공간을 필요로 하는 '트랜스포머' 아키텍처의 단점을 보완하기 위한 새로운 기술들을 잇달아 공개했습니다. 이는 '어텐션 메커니즘'이 발표된 지 7년 만에 이를 뛰어넘기 위한 시도가 본격화되고 있음을 보여줍니다.<br><br>
                        구글은 먼저 대형언어모델(LLM)의 컨텍스트 창 길이를 무한 확장할 수 있는 '인피니-어텐션(Infini-attention)' 기술에 관한 논문을 온라인 아카이브에 게재했습니다. '챗GPT'나 '제미나이' 등 LLM에 사용되는 트랜스포머 아키텍처는 컨텍스트 창이 커짐에 따라 필요한 메모리와 계산 시간이 기하급수적으로 증가하는 단점이 있습니다. 예를 들어, 입력 크기를 토큰 1000개에서 2000개로 확장하면 입력을 처리하는 데 필요한 메모리와 계산 시간이 두 배가 아닌 네 배로 늘어나게 됩니다. 이는 텍스트 내 토큰들의 상관관계를 밝혀내기 위해 입력 정보를 병렬로 처리하는 '어텐션 메커니즘' 때문입니다.<br><br>
                        이 문제를 해결하기 위해 구글은 메모리 및 컴퓨팅 요구 사항을 일정하게 유지하면서 LLM이 무한 길이의 텍스트를 처리할 수 있도록 인피니-어텐션 기술을 도입했습니다. 인피니-어텐션은 일반적인 어텐션 메커니즘에 '압축 메모리'를 통합하여, 입력이 컨텍스트 길이를 초과하면 모델이 계산 효율성을 위해 압축 메모리에 이전 어텐션 상태를 저장합니다. 전체 컨텍스트 기록을 유지하기 위해 다음 컨텍스트 길이를 처리할 때 이전 컨텍스트의 어텐션 상태를 버리지 않고 압축 메모리에 저장한다는 설명입니다.<br><br>
                        구글에 따르면 인피니-어텐션을 적용한 LLM은 메모리 추가 없이도 100만 개 이상의 토큰 품질을 유지할 수 있습니다. 연구진은 트랜스포머 아키텍처의 어텐션 메커니즘에 대한 미묘하지만 중요한 수정을 통해 기존 LLM을 무한히 긴 컨텍스트로 자연스럽게 확장할 수 있다고 설명했습니다. 또한, 인피니-어텐션이 매우 긴 컨텍스트에 대한 모델의 일관성을 측정하는 퍼플렉시티(Perplexity) 벤치마크에서 114배 더 적은 메모리를 사용하고도 다른 긴 컨텍스트 트랜스포머 기반 LLM을 능가하는 성능을 기록했다고 주장했습니다.<br><br>
                        무한한 컨텍스트 길이를 지원하는 LLM을 사용하면 이론적으로 모든 문서를 프롬프트에 삽입하고 모델이 각 쿼리에 대해 가장 관련성이 높은 답변을 선택하도록 할 수 있습니다. 또한, 특정 작업에 대한 성능을 향상하기 위해 모델을 세부적으로 조정할 필요 없이 긴 예제를 제공해 모델을 사용자 정의할 수도 있습니다.<br><br>
                        더불어 구글은 엣지 장치용 오픈 소스 소형언어모델(sLM) '리커런트젬마(RecurrentGemma)'에 관한 논문도 온라인 아카이브에 게재했습니다. 이 모델 역시 트랜스포머 아키텍처의 어텐션 메커니즘을 보완한 LLM과 동등한 수준의 성능을 유지하면서 메모리 및 처리 요구 사항을 대폭 축소한다는 내용입니다.<br><br>
                        트랜스포머는 입력 데이터를 모두 병렬로 처리하는 어텐션 메커니즘 때문에 데이터 볼륨이 증가함에 따라 메모리와 처리량이 크게 증가하는 약점이 있습니다. 이로 인해 LLM은 스마트폰이나 사물인터넷(IoT), 개인용 컴퓨터와 같이 리소스가 제한된 장치에 배포하기 어렵고, 데이터센터 내의 원격 서버에서 실행되기 때문에 실시간 응답을 요구하는 AI 애플리케이션에 적합하지 않습니다.<br><br>
                        반면 리커런트젬마는 트랜스포머 기반 모델처럼 모든 정보를 병렬로 처리하는 대신, 주어진 시간에 입력 데이터에 집중하여 처리하는 '로컬 어텐션 메커니즘'을 도입했습니다. 이로 인해 성능을 크게 저하시키지 않으면서 계산 부하를 줄이고 처리 속도를 높입니다. 리소스가 제한된 엣지 장치에 배포하는 데 적합하고 원격 서버에서 실행할 필요가 없어 실시간 엣지 어플리케이션에 적합하다는 설명입니다.<br><br>
                        리커런트젬마는 새로운 입력 데이터가 처리될 때 업데이트되는 '히든 스테이트(hidden state)'를 유지함으로써 이전 정보를 순차적으로 기억하는 순환 신경망(RNN)의 기본 구성 요소인 선형 반복(linear recurrence)을 어텐션과 결합하여, 입력 데이터에 관계없이 일정한 수준의 리소스 사용량을 유지하면서 확장된 텍스트를 처리할 수 있습니다. 특히 리커런트젬마는 처리 범위를 줄임으로써 대용량 데이터를 지속적으로 재처리하기 위한 GPU 필요성을 최소화합니다.<br><br>
                        하드웨어 요구 사항이 낮아짐에 따라 리커런트젬마와 같은 모델은 일반적으로 초대형 클라우드를 위해 설계된 서버보다 컴퓨팅 전력이 적은 엣지 컴퓨팅 응용 프로그램에 더 적합합니다. 이는 클라우드 연결에 의존하지 않고 스마트폰, IoT 장치 또는 임베디드 시스템과 같은 엣지 장치에 직접 언어모델을 실행할 수 있게 합니다.<br><br>
                        구글이 공개한 인피니-어텐션과 리커런트젬마는 트랜스포머 아키텍처의 한계를 극복하고 LLM의 활용 범위를 확장하는 데 기여할 것으로 보입니다. 인피니-어텐션은 무한한 길이의 컨텍스트를 처리할 수 있어 LLM의 응용 분야를 넓히고, 리커런트젠마는 엣지 장치에서 실시간으로 동작 가능한 소형 모델을 제공함으로써 AI 기술의 대중화에 기여할 것으로 기대됩니다.<br><br>
                        이러한 기술 혁신은 AI 분야의 경쟁이 얼마나 치열한지를 보여주는 동시에, 트랜스포머 아키텍처의 한계를 극복하기 위한 다양한 시도가 이루어지고 있음을 시사합니다. 앞으로도 AI 기술의 발전을 위해 새로운 아이디어와 접근 방식이 등장할 것으로 예상되며, 이를 통해 AI 기술의 성능과 활용 범위가 더욱 확대될 것으로 전망됩니다.<br><br>
                        <a href="https://www.aitimes.com/news/articleView.html?idxno=158799" target="_blank">2024년03월14일 : AI Times 구글, '트랜스포머' 보완할 기술 잇달아 공개…”메모리·시간 축소” </a> <br><br>
                </p>
        
                </li>
                <!-- 이곳에 더 많은 표현을 추가할 수 있습니다 -->
                </ul>



</main>


<footer>
   © 2023~2024 AI NEWS. All rights reserved.
   <a href="mailto:stberry7@gmail.com?subject=Hello&amp;body=Nice%20to%20meet%20you">
    Email me
   </a>
</footer>
<script>
   var clickCount = 0;
  </script>
<style>
.firework {
    position: absolute;
    width: 1px;
    height: 1px;
    border-radius: 50%;
    background: red;
    animation: explode 3s ease-out;
}

@keyframes explode {
    to {
        transform: scale(30);
        opacity: 0;
    }
}
</style>
<script>
var colors = ['#ffb3ba', '#ffdfba', '#ffffba', '#baffc9', '#bae1ff'];

document.addEventListener('click', function(event) {
    if (event.clientX < 30 || event.clientX > window.innerWidth - 30 ||
        event.clientY < 30 || event.clientY > window.innerHeight - 30) {
        return;
    }
    for (var i = 0; i < 10; i++) {
        var firework = document.createElement('div');
        firework.className = 'firework';
        // firework.style.top = (event.clientY - 0.5) + 'px';
        firework.style.top = (event.clientY+ window.scrollY - 0.5) + 'px';
        firework.style.left = (event.clientX - 0.5) + 'px';
        // firework.style.top = (event.clientY + window.scrollY - 0.5) + 'px'; // Adjusted for scroll
        firework.style.backgroundColor = colors[Math.floor(Math.random() * colors.length)];
        firework.style.transform = 'translate(' + (Math.random() * 200 - 100) + 'px, ' + (Math.random() * 200 - 100) + 'px)';
        document.body.appendChild(firework);
        setTimeout(function() {
            document.body.removeChild(firework);
        }, 3000);
    }
});
</script>
</body>
</html>
