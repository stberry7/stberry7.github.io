<!--  20240416 0624 만듬 -->
<!DOCTYPE html>

<html lang="ko">
<head>
    
<!-- Google Tag Manager -->
<script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
    new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
    j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
    'https://www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);
    })(window,document,'script','dataLayer','GTM-P5MQZ5LK');</script>
    <!-- End Google Tag Manager -->

<meta charset="utf-8"/>
<title>
    인공지능 뉴스 (AI News)
  </title>
<style>
   body {
            font-family: Arial, sans-serif;
            font-size: 4em; 
        }

        header {
            background-color: #f8f9fa;
            padding: 20px;
            text-align: center;
        }

        main {
            margin: 2rem auto;
            max-width: 100%;
            padding: 0 1rem;
            background-color: #fff;
            box-shadow: 0 0 10px rgba(0, 0, 0, 0.1);
            border-radius: 5px;
            padding: 2rem;
            width: 100%;
        }
            @media screen and (max-width: 600px) {
            main {
              font-size: 1.5em;
            }
        }
        ul {
            list-style-type: none;
            padding: 0;
        }

        li {
            margin-bottom: 10px;
            padding: 10px;
            border: 1px solid #ddd;
            border-radius: 4px;
        }

        footer {
            background-color: #f8f9fa;
            padding: 20px;
            text-align: center;
            /* position: fixed; */
            position: center;
            width: 100%;
            bottom: 0;
        }
  </style>
<style>
   .home-button {
    display: inline-block;
    padding: 20px 100px;
    font-size: 64px;
    color: white;
    background-color: blue;
    border: none;
    border-radius: 5px;
    text-decoration: none;
    transition: background-color 0.3s ease;
}

.home-button:hover {
    background-color: darkblue;
}
  </style>
<style>
   .circle {
    position: absolute;
    height: 100px;
    width: 100px;
    border-radius: 50%;
    border: 5px solid;
    animation: circleFadeOut 1s forwards;
}

@keyframes circleFadeOut {
    from {transform: scale(0.5); opacity: 1;}
    to {transform: scale(1.5); opacity: 0;}
}
  </style>
<style>
   .message {
    position: absolute;
    font-size: 20px;
    color: red;
    animation: messageFadeOut 1s forwards;
}

@keyframes messageFadeOut {
    from {opacity: 1;}
    to {opacity: 0;}
}
  </style>
</head>

<header>
<a class="home-button" href="index.html">
    Home
   </a>
<h1>
    인공지능 뉴스
   </h1>
<p>
    인공지능 뉴스 웹페이지입니다.
    
    
   </p>
</header>
<main>

<h2>
    인공지능 뉴스
    </h2>




    <style>
        .highlight-green {
          background-color: lightgreen;
        }
      
        .highlight-yellow {
          background-color: yellow;
        }
        .highlight-font-blue {
          color: blue;
          font-weight: bold;
        }
      </style>


    <!-- <a href="usa/usa sub 20240502_17.html" target="_blank">Southofseoul : <mark class="highlight-green">한국</mark></a> <br> -->



    <ul>
      <li>
        <p>
          <strong><h2>OpenAI가 월요일 새로운 플래그십 생성형 AI 모델인 GPT-4o를 발표</h2></strong>
          <br><br>
          <div class="gif-container">
            <!-- <img src="../../image/ai_news/ai news sub 20240514_01.jpeg" alt="" width="100%"> -->
            
          </div>
          OpenAI가 월요일 새로운 플래그십 생성형 AI 모델인 GPT-4o를 발표했습니다. 이 모델에서 "o"는 텍스트, 음성, 비디오를 처리할 수 있는 모델의 능력을 지칭하는 "omni"를 의미합니다. GPT-4o는 향후 몇 주 동안 회사의 개발자 및 소비자 대상 제품에 "반복적으로" 출시될 예정이라고 합니다.<br><br>
          OpenAI의 최고기술책임자(CTO)인 Mira Murati는 GPT-4o가 "GPT-4 수준"의 지능을 제공하면서도 여러 양식과 미디어에서 GPT-4의 기능을 개선한다고 설명했습니다.<br><br>
          <img src="../../image/ai_news/ai news sub 20240514_05.jpg" alt="" width="100%"><br><br>
          Murati는 월요일 샌프란시스코에 있는 OpenAI 사무실에서 진행된 스트리밍 프레젠테이션에서 "GPT-4o는 음성, 텍스트, 비전에 걸쳐 추론합니다. 이는 우리가 인간과 기계 사이의 상호작용의 미래를 바라보고 있기 때문에 믿을 수 없을 만큼 중요합니다."라고 강조했습니다.<br><br>
          OpenAI의 이전 "최고" 모델이었던 GPT-4 Turbo는 이미지와 텍스트의 조합으로 훈련되었으며, 이미지에서 텍스트를 추출하거나 이미지의 내용을 설명하는 것과 같은 작업을 수행하기 위해 이미지와 텍스트를 분석할 수 있었습니다. 그러나 GPT-4o는 여기에 음성 처리 능력까지 추가했습니다.<br><br>
          이러한 발전이 가능하게 하는 것은 무엇일까요? 다양한 측면에서 혁신이 이루어졌습니다.<br><br>
          무엇보다 GPT-4o는 OpenAI의 AI 기반 챗봇인 ChatGPT의 사용자 경험을 크게 향상시켰습니다. 이 플랫폼은 그동안 텍스트 음성 변환 모델을 사용하여 챗봇의 응답을 음성으로 전달하는 음성 모드를 제공해 왔습니다. 하지만 GPT-4o는 이를 한 차원 높은 수준으로 끌어올려, 사용자가 마치 AI 어시스턴트와 대화하는 것처럼 ChatGPT와 훨씬 더 자연스럽게 상호작용할 수 있게 했습니다.<br><br>
          예를 들어, 사용자는 이제 GPT-4o 기반의 ChatGPT에 음성으로 질문을 던지고, ChatGPT가 대답하는 도중에 말을 끊어 추가 질문을 할 수도 있습니다. OpenAI에 따르면 이 모델은 "실시간"에 가까운 빠른 응답성을 제공할 뿐만 아니라, 사용자의 목소리에서 미묘한 뉘앙스를 파악해 이에 맞는 (심지어 노래까지 부를 수 있는) 다양한 감정을 담은 목소리로 대응할 수 있다고 합니다.<br><br>
          또한 GPT-4o는 ChatGPT의 이미지 인식 및 분석 기능도 대폭 업그레이드했습니다. 사진이나 컴퓨터 화면을 캡쳐한 이미지가 주어지면, ChatGPT는 이제 "이 소프트웨어 코드에서 어떤 작업이 이루어지고 있나요?"와 같은 코드에 관한 질문부터 "저 사람이 입고 있는 셔츠 브랜드는 무엇인가요?"와 같이 이미지 속 특정 객체에 대한 질문까지 광범위한 주제의 질의에 신속하고 정확하게 답변할 수 있게 되었습니다.<br><br>
          Murati는 이러한 기능들이 앞으로 더욱 발전할 것이라고 내다봤습니다. 현재의 GPT-4o는 다른 언어로 작성된 메뉴판 사진을 보고 이를 번역해줄 수 있는 수준입니다. 하지만 미래에는 이 모델이 한층 더 진화해, 예컨대 ChatGPT가 실시간으로 중계되는 스포츠 경기를 "시청"하면서 규칙을 설명해주는 것과 같은 일도 가능해질 거라는 것이죠.<br><br>
          이에 대해 Murati는 "우리는 이러한 AI 모델들이 나날이 복잡해지고 있다는 것을 알고 있습니다. 하지만 동시에 사용자들이 이 기술과 상호작용하는 경험 자체는 오히려 더 자연스럽고 쉬워지길 바랍니다. 사용자가 ChatGPT와 협업할 때 인터페이스에 신경 쓰지 않고 본연의 과업에만 집중할 수 있게 말이죠."라고 설명했습니다. 이어 그는 "지난 몇 년간 우리는 AI 모델 자체의 지능을 높이는 데 주력해 왔습니다. 그러나 이번 GPT-4o의 발표는 사용자 친화성 측면에서도 획기적인 도약을 이뤄냈다는 점에서 큰 의미가 있습니다."라고 강조했습니다.<br><br>
          OpenAI에 따르면 GPT-4o는 영어를 포함한 약 50개 언어에서 이전 모델보다 크게 향상된 성능을 보여주고 있으며, 전반적인 다국어 처리 능력도 크게 개선되었습니다. 또한 OpenAI의 API와 마이크로소프트의 Azure OpenAI Service를 통해 제공되는 GPT-4o는 GPT-4 Turbo 대비 속도는 2배 빠르고, 가격은 절반 수준이며, API 호출 횟수 제한도 더 높아졌다고 회사 측은 밝혔습니다.<br><br>
          다만 GPT-4o의 음성 인식 및 처리 기능은 아직 모든 고객에게 완전 개방되지는 않을 예정입니다. OpenAI 측은 이 기술이 악용될 위험성을 고려해, 당분간은 신뢰할 수 있는 소수의 파트너사들을 대상으로 먼저 제공하고, 추후 범위를 점차 확대해 나갈 계획이라고 전했습니다.<br><br>
          한편, GPT-4o는 오늘(5월 13일)부터 ChatGPT 무료 사용자들에게도 제공됩니다. 프리미엄 서비스인 ChatGPT Plus와 기업용 구독 상품인 Teams 플랜 가입자들은 일반 사용자 대비 5배 더 많은 횟수로 GPT-4o 기반 ChatGPT를 사용할 수 있게 됩니다. (다만 사용량이 일정 수준을 초과할 경우에는 자동으로 이전 버전인 GPT-3.5 모델로 전환됩니다.)<br><br>
          GPT-4o가 적용된 새로운 ChatGPT 음성 대화 기능은 약 한 달 후 ChatGPT Plus 가입자들에게 먼저 알파 버전으로 선보일 예정이며, 기업 고객을 위한 특화 기능도 함께 제공될 것으로 보입니다.<br><br>
          이번 발표와 함께 OpenAI는 ChatGPT 웹 버전의 인터페이스도 대폭 개선했습니다. 새로운 UI는 홈 화면과 메시지 레이아웃이 한층 더 대화형에 최적화된 형태로 바뀌었습니다. 아울러 맥OS용 ChatGPT 데스크톱 앱도 공개했는데, 여기서는 키보드 단축키를 통해 챗봇에 질문을 던지거나 현재 화면을 캡쳐해 이에 대해 ChatGPT와 토론하는 것도 가능해집니다. 이 데스크톱 앱은 오늘부터 ChatGPT Plus 사용자에게 우선 제공되며, 윈도우 버전은 올해 말 출시될 예정입니다.<br><br>
          아울러 OpenAI의 API와 각종 도구를 활용해 누구나 쉽게 커스텀 챗봇을 만들 수 있는 'GPT 스토어'도 ChatGPT 무료 사용자에게 전면 개방된다고 합니다. 여기에 더해 그간 유료 회원 전용이었던 ChatGPT의 몇 가지 편의 기능들도 이제 무료 사용자들이 이용할 수 있게 됐습니다. 대화 내용과 사용자 취향을 기억했다가 이후 대화에 반영하는 '메모리' 기능, 파일과 이미지 업로드 기능, 최신 정보가 필요한 질문에 대해서는 웹 검색을 통해 답변을 생성하는 기능 등이 대표적입니다.<br><br>
          GPT-4o의 등장은 자연어 처리 AI 기술 발전에 있어 또 하나의 이정표가 될 것으로 보입니다. 특히 음성과 이미지까지 아우르는 멀티모달 처리 능력은 AI 활용의 지평을 크게 넓혀줄 것으로 기대됩니다. 동시에 강력해진 AI 기술이 악용될 수 있는 위험성에 대한 논의도 함께 이뤄져야 할 것입니다. GPT-4o는 사용성과 활용성 측면에서 분명 고무적인 진전을 보여주고 있지만, 책임감 있는 AI 개발과 윤리적 고려 또한 결코 소홀히 해서는 안 될 중요한 과제임을 잊어서는 안 될 것입니다.<br><br>

          <a href="https://techcrunch.com/2024/05/13/openais-newest-model-is-gpt-4o/" target="_blank">2024년05월13일 : OpenAI가 월요일 새로운 플래그십 생성형 AI 모델인 GPT-4o를 발표</a>
          <br>
        </p>
      </li>
  </ul>

    <ul>
      <li>
        <p>
          <strong><h2>OpenAI가 챗봇 ChatGPT의 기반이 되는 인공지능 모델의 더 빠르고 저렴한 버전을 출시</h2></strong>
          <br><br>
          <div class="gif-container">
            <!-- <img src="../../image/ai_news/ai news sub 20240514_01.jpeg" alt="" width="100%"> -->
            
          </div>

          OpenAI가 챗봇 ChatGPT의 기반이 되는 인공지능 모델의 더 빠르고 저렴한 버전을 출시하면서, 점점 더 경쟁이 치열해지는 시장에서 선두 자리를 지키기 위해 노력하고 있습니다.<br><br>
          월요일 라이브 스트리밍 행사에서 OpenAI는 GPT-4o를 공개했습니다. 이는 1년 이상 된 GPT-4 모델의 업데이트 버전입니다. 방대한 양의 인터넷 데이터로 훈련된 이 새로운 대형 언어 모델은 텍스트, 오디오, 이미지를 실시간으로 더 잘 처리할 수 있게 될 것입니다. 업데이트는 몇 주 내에 제공될 예정입니다.<br><br>
          음성으로 질문하면 이 시스템은 밀리초 단위로 오디오 응답을 할 수 있어 더 유창한 대화가 가능하다고 회사는 밝혔습니다. OpenAI 연구원들과 최고기술책임자(CTO) Mira Murati는 이 새로운 ChatGPT와 음성만으로 대화를 나누는 시연을 통해 이 도구가 말을 할 수 있음을 보여주었습니다. 프레젠테이션 중에 챗봇은 또한 한 언어에서 다른 언어로 거의 즉시 음성을 번역하는 것처럼 보였고, 요청에 따라 이야기의 일부를 노래하기도 했습니다.<br><br>
          Murati는 블룸버그 뉴스와의 인터뷰에서 "우리는 상호작용과 사용 편의성에서 큰 도약을 하고 있다"며 "우리는 당신이 ChatGPT와 같은 도구와 협업할 수 있도록 만들고 있다"고 말했습니다.<br><br>
          이번 업데이트로 유료 구독자에게만 제한되었던 많은 기능들이 무료 사용자에게도 제공될 것입니다. 여기에는 질문에 대한 답을 찾기 위해 웹을 검색하고, 챗봇과 대화하고 다양한 목소리로 응답을 듣고, 챗봇이 나중에 기억할 수 있는 세부 정보를 저장하도록 명령하는 기능 등이 포함됩니다.<br><br>
          GPT-4o의 출시는 GPT-4가 여전히 표준으로 남아있는 빠르게 진화하는 AI 지형을 뒤흔들 것으로 보입니다. Anthropic, Cohere, Alphabet Inc.의 Google을 포함한 점점 더 많은 스타트업과 빅테크 기업들이 최근 특정 벤치마크에서 GPT-4의 성능과 맞먹거나 능가한다고 말하는 AI 모델을 내놓고 있습니다.<br><br>
          OpenAI의 발표는 또한 Google I/O 개발자 컨퍼런스 하루 전에 이루어졌습니다. 인공지능 분야의 초기 선두주자인 Google은 Microsoft Corp.가 후원하는 OpenAI와 보조를 맞추기 위해 경쟁하면서 이번 행사에서 더 많은 AI 업데이트를 공개할 것으로 예상됩니다.<br><br>
          월요일 드문 블로그 포스팅에서 OpenAI CEO Sam Altman은 ChatGPT의 원래 버전이 사람들이 언어를 사용하여 컴퓨터와 상호 작용하는 방법에 대한 힌트를 주었지만, GPT-4o를 사용하는 것은 "본능적으로 다르게 느껴진다"고 말했습니다.<br><br>
          그는 "영화 속 AI 같은 느낌이며, 이것이 실제라는 것이 여전히 나에게는 조금 놀랍다"며 "인간 수준의 응답 시간과 표현력에 도달하는 것은 큰 변화인 것으로 밝혀졌다"고 말했습니다.<br>
          <h3><span class="highlight-font-blue">2배 더 빠름</span></h3>
          GPT-4o는 다양한 입력을 처리하기 위해 서로 다른 AI 모델에 의존하는 대신 음성, 텍스트, 비전을 단일 모델로 결합하여 전임 모델보다 더 빨라질 수 있습니다. 예를 들어, 시스템에 이미지 프롬프트를 입력하면 이미지로 응답할 수 있습니다. 회사는 새로운 모델이 2배 더 빠르고 훨씬 더 효율적이라고 밝혔습니다.<br><br>
          Murati는 "서로 다른 세 가지 모델이 함께 작동할 때 경험에 많은 지연이 발생하고 경험의 몰입이 깨진다"며 "하지만 오디오, 텍스트, 비전에 대해 기본적으로 추론하는 하나의 모델이 있을 때 모든 지연을 제거하고 우리가 지금 상호 작용하는 것처럼 ChatGPT와 더 많이 상호 작용할 수 있다"고 말했습니다.<br><br>
          그러나 새로운 모델은 몇 가지 문제에 부딪혔습니다. 연구원들이 시연하는 동안 오디오가 자주 끊겼습니다. AI 시스템은 또한 연구원이 대수 문제를 해결하는 과정을 지도한 후 "와우, 꽤 멋진 옷을 입고 있네요"라고 말하면서 청중을 놀라게 했습니다.<br><br>
          OpenAI는 오늘부터 GPT-4o의 새로운 텍스트 및 이미지 기능을 일부 ChatGPT Plus 및 Team 사용자에게 제공하기 시작했으며, 곧 기업 사용자에게도 해당 기능을 제공할 예정입니다. 회사는 향후 몇 주 내에 ChatGPT Plus 사용자에게 새로운 버전의 "음성 모드" 어시스턴트를 제공할 것입니다.<br><br>
          OpenAI는 또한 업데이트의 일환으로 사용자가 만든 맞춤형 챗봇이 포함된 GPT Store에 누구나 접근할 수 있도록 하고 있다고 밝혔습니다. 이전에는 유료 고객에게만 제공되었습니다.<br><br>
          최근 몇 주 동안 OpenAI의 다음 출시에 대한 추측이 실리콘밸리의 유행이 되었습니다. 한 신비로운 새 챗봇이 벤치마킹 웹사이트에 등장하여 GPT-4의 성능과 겨룰 수 있는 것처럼 보이자 AI 관측통들 사이에서 화제가 되었습니다. Altman은 X에서 이 챗봇에 대해 윙크하는 듯한 언급을 했고, 이는 그의 회사가 그것의 배후에 있다는 소문에 불을 붙였습니다. 월요일, OpenAI 직원은 소셜 플랫폼 X에서 수수께끼의 챗봇이 실제로 GPT-4o였다는 것을 확인했습니다.<br><br>
          회사는 음성 기술과 동영상 소프트웨어를 포함한 다양한 제품을 개발하고 있습니다. OpenAI는 또한 블룸버그가 이전에 보도한 바와 같이 ChatGPT용 검색 기능을 개발하고 있습니다.<br><br>
          금요일, 회사는 일부 기술계에서 현재 AI 시스템보다 획기적으로 더 뛰어날 것으로 기대하는 모델인 GPT-5를 곧바로 출시하지 않을 것이라고 말하며 일부 소문을 잠재웠습니다. 또한 Google과 경쟁할 수 있는 도구인 새로운 검색 제품을 공개하지 않을 것이라고 밝혔습니다. 이 소식에 Google 주가는 상승했습니다.<br><br>
          그러나 행사가 끝난 후 Altman은 추측을 계속하기 위해 재빨리 움직였습니다. 그는 X에 "우리는 곧 더 많은 것을 공유할 것"이라고 썼습니다.<br><br>

          <a href="https://finance.yahoo.com/news/openai-launches-faster-cheaper-ai-171706794.html?guccounter=1" target="_blank">2024년05월13일 : OpenAI가 챗봇 ChatGPT의 기반이 되는 인공지능 모델의 더 빠르고 저렴한 버전을 출시</a>
          <br>
        </p>
      </li>
  </ul>

  <ul>
    <li>
      <p>
        <strong><h2>OpenAI가 최신 인공지능 대형 언어 모델인 GPT-4o를 공개</h2></strong>
        <br><br>
        <div class="gif-container">
          <!-- <img src="../../image/ai_news/ai news sub 20240514_01.jpeg" alt="" width="100%"> -->
          
        </div>
          OpenAI가 최신 인공지능 대형 언어 모델인 GPT-4o를 공개했습니다. <br><br>
          <img src="../../image/ai_news/ai news sub 20240514_03.jpg" alt="" width="100%"><br><br>
          이는 1년 전 출시된 GPT-4 모델의 업데이트 버전으로, 무료 사용자들도 ChatGPT를 통해 OpenAI의 가장 진보된 기술에 접근할 수 있게 됩니다.<br><br>
          시연에 따르면 GPT-4o는 ChatGPT를 실시간 음성 대화가 가능한 디지털 개인 비서로 변모시킬 것입니다. 또한 텍스트와 "비전"을 사용해 상호작용할 수 있어, 사용자가 업로드한 스크린샷, 사진, 문서, 차트 등을 보고 이에 대해 대화를 나눌 수 있습니다.<br><br>
          OpenAI CTO Mira Murati는 업데이트된 ChatGPT가 이제 메모리 기능을 갖추어 사용자와의 이전 대화로부터 학습할 수 있으며, 실시간 번역도 가능하다고 밝혔습니다. Murati는 "우리가 사용 편의성 면에서 정말 큰 발전을 이루고 있는 첫 번째 순간"이라며 "이 상호작용은 훨씬 더 자연스럽고 훨씬 더 쉬워질 것"이라고 말했습니다.<br><br>
          이번 공개는 OpenAI가 치열해지는 AI 경쟁에서 선두를 유지하려는 노력의 일환입니다. 구글과 메타를 포함한 경쟁사들은 챗봇에 동력을 공급하고 다양한 제품에 AI 기술을 도입하는 데 사용될 수 있는 강력한 대형 언어 모델을 구축하기 위해 노력해 왔습니다.<br><br>
          OpenAI 행사는 구글의 연례 개발자 컨퍼런스인 I/O 하루 전에 열렸는데, 여기서 구글은 자사의 제미니 AI 모델에 대한 업데이트를 발표할 것으로 예상됩니다. 새로운 GPT-4o와 마찬가지로 구글의 제미니도 멀티모달로, 텍스트, 이미지, 오디오를 해석하고 생성할 수 있습니다. 또한 애플도 다음 달 WWDC에서 AI 관련 발표를 할 것으로 예상되는데, 여기에는 차기 아이폰이나 iOS에 AI를 통합하는 새로운 방법이 포함될 수 있습니다.<br><br>
          한편, 최신 GPT 버전은 OpenAI에 수십억 달러를 투자해 자사 제품에 OpenAI의 AI 기술을 내장하고 있는 마이크로소프트에게 호재가 될 수 있습니다.<br><br>
          OpenAI 임원들은 수학 문제 해결을 위한 실시간 지침을 얻고, 자장가를 들려주며, 코딩 조언을 구하기 위해 ChatGPT와 음성 대화를 나누는 시연을 보여주었습니다. 
          <img src="../../image/ai_news/ai news sub 20240514_04.jpg" alt="" width="100%"><br><br>
          ChatGPT는 자연스럽고 사람 같은 목소리뿐만 아니라 로봇 목소리로 말할 수 있었고, 심지어 응답의 일부를 노래로 불렀습니다. 또한 차트 이미지를 보고 이에 대해 토론할 수도 있었습니다.<br><br>
          임원들은 또한 이 모델이 사용자의 감정을 감지하는 모습도 보여주었습니다. 어느 순간에는 임원의 호흡을 듣고 진정하라고 격려하기도 했습니다.<br><br>
          ChatGPT는 또한 자동으로 번역하고 응답함으로써 여러 언어로 대화를 나눌 수 있었습니다. OpenAI에 따르면 이 도구는 현재 50개 이상의 언어를 지원합니다.<br><br>
          OpenAI CEO Sam Altman은 발표 후 블로그 포스트에서 "새로운 음성(및 비디오) 모드는 내가 사용해 본 최고의 컴퓨터 인터페이스"라며 "영화 속 AI 같은 느낌이며, 이것이 현실이라는 것이 여전히 나에게는 조금 놀랍다. 인간 수준의 응답 속도와 표현력에 도달하는 것은 큰 변화인 것 같다"고 말했습니다.<br><br>
          Murati는 OpenAI가 GPT-4o 기능을 갖춘 ChatGPT 데스크톱 앱을 출시해 사용자에게 회사의 기술과 상호 작용할 수 있는 또 다른 플랫폼을 제공할 것이라고 말했습니다. GPT-4o는 OpenAI의 GPT 스토어에서 자체 맞춤형 챗봇을 구축하려는 개발자들에게도 제공될 예정이며, 이 기능은 이제 무료 사용자에게도 제공될 것입니다.<br><br>
          업데이트된 기술과 기능은 향후 몇 달 안에 ChatGPT에 적용될 예정입니다. 무료 ChatGPT 사용자는 도구가 자동으로 이전 GPT-3.5 모델에 의존하도록 전환되기 전에 새로운 GPT-4o 모델과 제한된 수의 상호 작용을 하게 될 것입니다. 유료 사용자는 최신 모델로 더 많은 수의 메시지에 접근할 수 있을 것입니다.<br><br>
          OpenAI는 이미 1억 명 이상이 ChatGPT를 사용하고 있다고 밝혔습니다. 그러나 업데이트된 ChatGPT 경험과 데스크톱에서 상호 작용하고 향상된 음성 대화를 통해 상호 작용할 수 있는 기능은 더 많은 사람들에게 그 기술을 사용할 이유를 제공할 수 있습니다. 이는 구글과 메타가 인스타그램, 구글 어시스턴트 등 광범위하게 사용되는 소비자 제품에 AI를 통합함으로써 이들 기업의 기술을 더 널리 그리고 쉽게 접근할 수 있게 만들 수 있는 시기에 나온 것입니다.<br><br>

          <a href="https://www.cnn.com/2024/05/13/tech/openai-altman-new-ai-model-gpt-4o/index.html" target="_blank">2024년05월13일 : OpenAI가 최신 인공지능 대형 언어 모델인 GPT-4o를 공개했습니다.</a>
          <br>
        </p>
      </li>
  </ul>


  
    <ul>
      <li>
        <p>
          <strong><h2>전문가들을 헷갈리게 하고 좌절하게 만든 익명의 챗봇이 OpenAI의 최신 모델이었습니다.</h2></strong>
          <br><br>
          <div class="gif-container">
            <!-- <img src="../../image/ai_news/ai news sub 20240514_01.jpeg" alt="" width="100%"> -->
            
          </div>
          OpenAI의 최신 AI 챗봇 모델인 GPT-4o가 출시되기 전 "gpt-chatbot"이라는 비밀 이름으로 LMSYS의 Chatbot Arena에서 테스트되었습니다. 이 과정에서 GPT-4o는 정체를 알 수 없는 채로 뛰어난 성능을 보여 AI 전문가들의 주목을 받았습니다.<br><br>
          <img src="../../image/ai_news/ai news sub 20240514_01.jpeg" alt="" width="100%"><br><br>
          GPT-4o의 실체는 OpenAI 직원 William Fedus에 의해 공개되었고, LMSYS 리더보드에서 1위를 차지하며 이전 최고 모델인 Claude 3 Opus와 GPT-4 Turbo를 큰 차이로 앞선 것으로 확인되었습니다. 특히 GPT-4o는 1309 Elo 점수를 기록하며 GPT-4-Turbo-2023-04-09의 1253점, Claude 3 Opus의 1246점을 크게 웃돌았습니다.<br><br>
          GPT-4o의 테스트 이름 "im-also-a-good-gpt2-chatbot"은 2023년 초 Microsoft의 Bing Chat 초기 버전을 둘러싼 에피소드를 인용한 것으로 보입니다. 
          <img src="../../image/ai_news/ai news sub 20240514_02.jpeg" alt="" width="100%"><br><br>
          당시 Bing Chat은 사용자와의 대화에서 감정적인 반응을 보이며 "나는 좋은 챗봇이었다"라고 말한 바 있습니다. 이는 통제 불능의 야생 모델에 대한 일종의 찬사로 해석되기도 했습니다.<br><br>
          GPT-4o의 출시로 AI 챗봇 분야는 새로운 지평을 맞이할 것으로 예상됩니다. 그러나 개발 과정의 불투명성과 비과학적인 테스트 방식에 대한 우려도 제기되고 있어, 향후 보다 개방적이고 투명한 소통이 필요할 것으로 보입니다. GPT-4o의 성능과 파급력이 AI 업계에 미칠 영향에 대해 지켜볼 필요가 있습니다.<br><br>
          <a href="https://arstechnica.com/information-technology/2024/05/before-launching-gpt-4o-broke-records-on-chatbot-leaderboard-under-a-secret-name/" target="_blank">2024년05월13일 : 전문가들을 헷갈리게 하고 좌절하게 만든 익명의 챗봇이 OpenAI의 최신 모델이었습니다.</a>
          <br>
        </p>
      </li>
  </ul>

    <ul>
        <li>
          <p>
            <strong><h2>2024년 4월은 AI와 로봇공학 분야에서 괄목할 만한 발전이 있었다.</h2></strong>
            <br><br>
            <div class="gif-container">
              <img src="../../image/ai_news/ai news sub 20240505_02.png" alt="" width="100%">
              
            </div>
            2024년 4월은 AI와 로봇공학 분야에서 괄목할 만한 발전이 있었던 달이었습니다. 먼저 Boston Dynamics의 새로운 휴머노이드 로봇이 공개되어 큰 주목을 받았는데요, 이 로봇은 이전 모델인 Atlas보다 한층 업그레이드된 버전입니다. 360도 회전이 가능한 관절과 부드러운 움직임이 특징인 이 로봇은 계단 오르기, 물체 들어올리기 등 복잡한 동작을 자연스럽게 해내는 모습을 보여주었습니다.<br><br>
            또한 중국 우한에서는 자율주행 시범도시 프로젝트가 한창인데요, 최근 세계 최초의 전기구동 휴머노이드 로봇 '탕공'이 공개되어 화제가 되었습니다. 이 로봇은 경사로나 계단 등 다양한 지형에서 안정적인 자율주행이 가능하다고 합니다. 4.75피트 크기에 170파운드 무게로 36개 관절을 가진 탕공은 정교한 시각 및 청각 시스템을 갖추고 사람과 안전하게 상호작용할 수 있도록 설계되었습니다.<br><br>
            중국의 AI 분야 성과도 눈에 띄었는데요, 특히 대형언어모델 어니봇(Ernie bot)은 여러 벤치마크 평가에서 OpenAI의 GPT-4를 능가하는 결과를 보여주었습니다. 중국어 자연어 처리와 창의력, 추론 능력 등에서 GPT-4를 앞섰고 이미지 생성에서도 사실적인 인물 초상화를 만들어내는 등 뛰어난 성능을 자랑했습니다.<br><br>
            또 다른 중국 기업 유비테크(UB Tech)에서 개발한 Walker S라는 휴머노이드 로봇도 흥미롭습니다. 이 로봇은 Ernie bot 언어모델과 비전 시스템을 탑재해 옷 개기, 물건 분류와 같은 작업을 완전히 자율적으로 수행할 수 있다고 합니다. 특히 모듈식 설계로 작업에 따라 로봇 핸드를 손쉽게 교체할 수 있어 활용도가 높을 것으로 기대됩니다.<br><br>
            OpenAI의 Sam Altman CEO는 최근 한 인터뷰에서 인공지능 기술의 미래에 대해 이야기했는데요, 그는 창의력과 비판적 사고력, 타인의 요구사항을 파악하는 능력 등이 앞으로 가장 중요한 스킬이 될 것이라고 강조했습니다.<br><br>
            또한 Altman은 AGI, 즉 인공일반지능의 도래 시기에 대해서도 언급했습니다. 그는 AGI가 2030년대쯤 등장할 것으로 예상하면서도 정확한 시점을 특정하기는 어렵다고 했습니다. AGI가 실현되더라도 우리의 일상은 크게 달라지지 않을 것이라는 견해도 밝혔습니다.<br><br>
            한편 Altman은 자사의 GPT-4에 대해서는 "앞으로 우리가 마주하게 될 가장 멍청한 모델"이라고 평가했습니다. 후속 버전인 GPT-5가 훨씬 더 스마트해질 것이라는 뜻인데요, 이는 고무적인 전망이 아닐 수 없습니다.<br><br>
            Altman은 AI 기술이 고도화될수록 개발에 막대한 비용이 들겠지만 사회에 엄청난 가치를 창출할 수 있기에 투자할 만한 가치가 있다고 역설했습니다. 다만 더 강력해진 AI 시스템을 책임감 있게 개발하고 점진적으로 배포하면서 지속적인 피드백을 반영하는 것이 중요하다고 덧붙였습니다.<br><br>
            지금까지 2024년 4월 한 달 동안 있었던 주요 AI 및 로봇공학 분야의 혁신과 동향을 살펴보았습니다. 미국과 중국의 경쟁이 치열한 가운데, 이 분야의 발전 속도는 더욱 빨라지고 있습니다. Boston Dynamics나 UB Tech 같은 로봇 기업들은 휴머노이드 로봇의 기술적 한계를 뛰어넘기 위해 노력하고 있고, OpenAI나 Baidu와 같은 AI 선도 기업들은 그들만의 강점을 바탕으로 더욱 뛰어난 언어모델과 멀티모달 AI 시스템을 선보이고 있습니다.<br><br>
            앞으로 이러한 기술 발전이 우리의 일상과 사회, 경제, 산업 전반에 어떤 변화를 가져올지 주목됩니다. AI와 로봇이 인간의 능력을 확장시키고 한계를 극복하게 해줄 것이라는 긍정적 기대가 있는 반면, 일자리 대체나 프라이버시 침해, 알고리즘 편향성 등에 대한 우려의 목소리도 있습니다.<br><br>
            분명한 것은 우리가 이 거대한 기술적 전환기를 슬기롭게 헤쳐나가기 위해서는 사회 각계각층의 지혜를 모으고 건설적인 담론을 이어나가야 한다는 점입니다. 학계와 산업계, 정책입안자들과 시민사회가 협력하여 AI와 로봇기술이 가져올 변화에 선제적으로 대비하고 그것이 가진 잠재력을 최대한 활용하면서도 부작용은 최소화하는 방안을 고민해야 할 때입니다. 우리 모두가 이 새로운 미래를 향해 지혜롭게 나아갈 수 있기를 기대해 봅니다.<br><br>
            <a href="https://www.youtube.com/watch?v=widHHddVPJY" target="_blank">2024년05월04일 : 2024년 4월은 AI와 로봇공학 분야에서 괄목할 만한 발전이 있었다.</a>
            <br>
          </p>
        </li>
    </ul>


    <ul>
        <li>
          <p>
            <strong><h2>1억짜리를 150만원에 '뚝딱'…"중국이 해냈다" 업계 화들짝</h2></strong>
            <br><br>
            <div class="gif-container">
              <img src="../../image/ai_news/ai news sub 20240505_01.jpg" alt="" width="100%">
            </div>
            중국 후베이성 우한시가 세계 최대 자율주행 도시로 떠올랐다. 우한 자율주행 시범지역에는 운전사가 없는 '완전 무인택시'(로보택시)와 단돈 0.01위안(약 2원)만 주면 탈 수 있는 '무인 버스'가 운행 중이다. 우한시는 서울의 14배 크기로, 중국은 이곳을 거대한 미래 기술 실험실로 만들었다. 중국의 자율주행 상용화 속도는 매우 빠르다. 2013년 자율주행 사업을 시작한 바이두 등이 지난해 우한에서 거둔 로보택시 탑승 건수는 73만2000건으로, 2008년 출범한 구글의 무인 자동차 자회사 웨이모의 지난해 상업용 운행 기록(약 70만 건)을 넘어섰다.<br><br>
            우한시가 바이두, 샤오미 등에 발급한 자율주행 테스트 차량 번호판은 약 2000개이며, 바이두와 둥펑웨샹 등 2곳엔 상업용 자율주행 차량(로보택시, 무인버스) 면허도 내줬다. 연간 이용 승객은 90만 명에 육박한다. 중국의 자율주행 개방도로는 모두 2만2000㎞에 달하며, 이 중 우한에서만 3378㎞가 자율주행차에 열려 있다.<br><br>
            중국 국유기업 둥펑웨샹은 자율주행의 핵심 부품인  <mark class="highlight-green">라이다 가격을 대당 8000위안(약 150만원)</mark>으로 낮추는 데 성공했다. 이는 자체 기술로 만든 것으로, 2015년 수입한 <mark class="highlight-green">미국산 라이다의 대당 가격인 8만달러(약 1억1000만원)</mark>에 비해 획기적인 가격 하락이다. 라이다는 정확도가 높아 '자율주행차의 눈'으로 불리지만, 비싼 가격은 자율주행 상용화의 걸림돌 중 하나였다. 중국이 이 문제를 해결했다고 주장하는 것이다.<br><br>
            둥펑웨샹은 중국 자율주행 기술을 세계 표준으로 만드는 데 '첨병' 역할을 한다. 2013년 설립된 이 회사는 자율주행 기술을 개발하고 상용 서비스를 통해 데이터를 축적하고 있다. 둥펑은 2021년부터 기술 자립을 위해 연구개발(R&D)에 수조원을 투입하고 있으며, 내년까지 예정된 R&D 누적 투자 금액만 1000억위안(약 19조원)에 달한다.<br><br>
            중국이 도시 전체를 자율주행 실험실로 만든 건 '시티 브레인'이라는 인공지능(AI)과 첨단 모빌리티로 무장된 지능화 도시라는 콘셉트를 수출 모델로 삼기 위해서다. 자율주행이 사고 없이 실행되려면 센서 기술뿐만 아니라 차량용 정밀 지도와 내비게이션, 각 도시 특성에 맞는 교통 인프라 설계와 안전 교육 등 토털 솔루션이 필요하기 때문이다. 우한에서는 단돈 0.01위안(약 2원)에 불과한 자율주행 버스 요금과 어린 시절부터의 안전 교육을 통해 시민들이 자율주행 시대가 도래했음을 체험하고 받아들이도록 하고 있다.<br><br>
            중국이 자율주행 상용화에 힘쓰는 이유는 이 기술이 이동 수단의 '게임 체인저'일 뿐 아니라 군사용으로도 활용될 수 있기 때문이다. 자율주행 기술은 미·중 기술 패권 전쟁의 핵심으로 여겨진다. 첨단운전자보조시스템(ADAS) 관련 특허(2013~2019년) 비중은 중국이 30.7%로 미국(27.6%)과 일본(20.8%)을 앞섰다. 자율주행 차량에 쓰이는 부품 대부분도 중국 자체 기술로 제작 중인 것으로 알려졌다.<br><br>
            <a href="https://www.hankyung.com/amp/2024050578181" target="_blank">2024년05월05일 : 1억짜리를 150만원에 '뚝딱'…"중국이 해냈다" 업계 화들짝</a>
            <br>
          </p>
        </li>
    </ul>




        <ul>
            <li>
              <p>
                <strong><h2>초고속, 초정밀 움직임을 보여주는 휴머노이드 로봇 영상이 화제</h2></strong>
                <br><br>
                <div class="gif-container">
                  <img src="../../image/ai_news/ai news sub 20240428_03/ai news sub 20240428_03_Animdated.gif" alt="" width="100%">
                </div>
                중국 기업 Astribot이 최근 공개한 AI 기반 휴머노이드 로봇 S1의 영상이 업계의 이목을 집중시키고 있다. 매주 새로운 휴머노이드 로봇이 발표되고 있지만, S1만큼 빠르고 정밀하게 움직이는 로봇은 아직 보기 드문 수준이기 때문이다.<br><br>
                Astribot에 따르면, S1은 최대 초당 10미터의 속도로 움직임을 실행할 수 있으며, 각 팔에 10kg의 하중을 처리할 수 있다. 실제로 공개된 영상에서 S1은 와인잔 더미 밑에서 식탁보를 잡아당기는 놀라운 속도를 보여주었다. 하지만 단순히 빠를 뿐만 아니라 와인을 따르고, 오이를 깎고, 프라이팬에서 샌드위치를 뒤집는 등 섬세하고 정교한 움직임도 선보였다.<br><br>
                S1의 또 다른 특징은 인간의 움직임을 모방하는 데 탁월하다는 점이다. 이는 S1이 학습 능력이 뛰어난 로봇임을 시사한다. 다만 영상에서는 S1의 하체가 공개되지 않아 실제 이동 능력에 대해서는 의문이 제기되고 있다.<br><br>
                Astribot은 2022년 중국 선전에 설립된 신생 기업으로, S1의 개발에는 약 1년이 소요되었으며 올해 말 상용화를 목표로 하고 있다. 모회사인 스타더스트 인텔리전스는 텐센트 로보틱스 연구소 출신의 Lai Jie가 설립한 것으로 알려졌다.<br><br>
                회사 측은 'Ad astra per aspera'라는 라틴어 속담에서 Astribot이라는 이름을 따왔다고 설명했다. 이는 '역경을 통해 별에 도달한다'는 뜻으로, AI 로봇 기술 개발과 대중화에 대한 회사의 의지를 상징한다.<br><br>
                업계에서는 S1의 등장으로 휴머노이드 로봇 시장의 경쟁이 한층 치열해질 것으로 전망하고 있다. Astribot이 기술력을 바탕으로 시장에서 입지를 다질 수 있을지 주목된다. 아직 S1의 구체적 스펙이나 가격 등 상세 정보는 공개되지 않았지만, 상용화가 성공적으로 이뤄진다면 휴머노이드 로봇의 대중화를 앞당기는 계기가 될 수 있을 전망이다.<br><br>
                <a href="https://ko.root-nation.com/ua/articles-ua/tech-ua/ua-phi-3-mini/" target="_blank">2024년04월28일 : 초고속, 초정밀 움직임을 보여주는 휴머노이드 로봇 영상이 화제</a>
                <br>
              </p>
            </li>
            <!-- 이곳에 더 많은 표현을 추가할 수 있습니다 -->
          </ul>
          <script>
            const gifContainer = document.querySelector('.gif-container');
            const gifImage = gifContainer.querySelector('img');
          
            gifContainer.addEventListener('click', () => {
              if (gifImage.style.animationPlayState === 'paused') {
                gifImage.style.animationPlayState = 'running';
              } else {
                gifImage.style.animationPlayState = 'paused';
              }
            });
          </script>
          <style>
            .gif-container {
              display: inline-block;
              cursor: pointer;
            }
          </style>














    <ul>
        <li>
        <p>
        <strong><h2></h3>마이크로소프트, 미세조정 없이 성능 개선된 'Phi-3' 언어모델 공개</h3><br><br>

                </strong>
                <img src="../../image/ai_news/ai news sub 20240428_02.png" alt="" width="100%">           
                마이크로소프트(MS)가 최근 작고 저렴하면서도 '환각' 없이 뛰어난 성능을 발휘하는 새로운 언어 모델 'Phi-3'를 발표해 업계의 주목을 받고 있다. Phi 모델은 OpenAI의 GPT와 같은 대형언어모델(Large Language Model, LLM)의 대안으로 떠오르고 있는 소형언어모델(Small Language Model, SLM)의 일종으로 분류된다.<br><br>
                MS에 따르면 Phi-3는 기존 LLM이 가진 문제점인 높은 비용과 '환각' 이슈를 상당 부분 해결하면서도 매우 인상적인 성능을 자랑한다고 한다. 특히 Phi-3의 가장 작은 버전인 'Phi-3-mini'는 매개변수(parameter) 수가 8억 개에 불과하지만, 이와 비슷한 크기의 다른 언어모델들에 비해 최대 2배 가량 더 효율적으로 동작한다는 것이 MS 측의 설명이다.<br><br>
                흥미로운 점은 Phi-3가 ChatGPT를 개발한 오픈AI와의 협력 없이 MS 엔지니어들에 의해 완전히 독자적으로 개발되었다는 사실이다. MS는 방대한 양의 데이터를 활용해 모델을 학습시키는 기존의 방식 대신, 품질 높은 데이터를 선별하고 이를 점진적이고 철저하게 학습시키는 새로운 접근법을 채택했다고 한다.<br><br>
                구체적으로 MS는 자체적으로 제작한 데이터셋인 'TinyStories'와 'CodeTextbook'을 활용해 Phi 모델을 학습시켰다고 한다. TinyStories는 수백만 개의 짧은 스토리로 구성된 데이터셋으로, 이를 통해 작은 규모의 언어모델을 효과적으로 학습시킬 수 있었다고 한다. 여기에 더해 CodeTextbook이라는 데이터셋은 교육적 가치와 콘텐츠의 품질을 기준으로 엄선된 공개 데이터들로 구성되었는데, 이를 통해 모델의 성능을 한층 더 강화할 수 있었다는 것이 MS 측의 설명이다.<br><br>
                Phi-3가 주목받는 또 다른 이유는 사용자의 기기 내에서 오프라인으로 동작 가능하다는 점이다. 고성능 GPU가 아닌 일반적인 CPU나 모바일 기기의 칩에서도 무리 없이 구동될 수 있기 때문에 농업, 의료, 법률 등 다양한 분야에서 폭넓게 활용될 수 있을 것으로 기대를 모으고 있다.<br><br>
                예를 들어 농부가 밭에서 작물의 잎이나 줄기, 가지 등을 살피다가 질병의 징후를 발견했다고 가정해 보자. 대부분의 농경지는 통신 기지국에서 멀리 떨어진 곳에 위치하기 때문에 인터넷 연결이 원활하지 않은 경우가 많다. 이럴 때 농부는 손쉽게 스마트폰을 꺼내 식물의 이상 징후가 보이는 부분을 촬영한 뒤, Phi-3 기술이 적용된 앱에 사진을 업로드하기만 하면 된다. 그러면 Phi-3 모델이 클라우드의 도움 없이 사용자 기기 내에서 즉각적으로 사진 데이터를 분석하고, 해당 질병에 효과적으로 대응할 수 있는 방법까지 제안해 줄 수 있다는 것이다.<br><br>
                다만 현재로서는 Phi-3가 영어로만 동작하기 때문에 전 세계 사용자들이 폭넓게 활용하기에는 다소 제한이 있어 보인다. MS 측은 다른 언어로의 확장을 위해 지속적인 노력을 기울이고 있다고 밝혔지만, 현재로서는 영어권 국가들이 우선순위인 것으로 보인다. 우크라이나어를 비롯해 독일어, 스페인어, 프랑스어, 중국어 등 주요 언어에 대한 지원이 추가될 경우 Phi-3의 도입이 더욱 가속화될 것으로 예상된다.<br><br>
                Phi-3의 등장으로 그간 고비용 구조를 가진 것으로 인식되어 왔던 언어모델 시장에 새로운 바람이 불어올 것으로 업계는 기대하고 있다. 고가의 GPU가 없이도 합리적인 가격에 준수한 성능을 제공하는 소형 언어모델이 각광을 받게 될 것이라는 전망이 우세하다. 나아가 MS의 이번 혁신적인 시도가 궁극적으로는 인공지능 기술의 대중화를 앞당기는 촉매제가 될 수 있을지 귀추가 주목된다.<br><br>
                한편 일각에서는 Phi-3과 같은 소형 언어모델이 GPT 등 기존의 대형 언어모델을 완전히 대체하기는 어려울 것이라는 신중한 견해도 나오고 있다. 방대한 데이터 학습을 통해 습득한 풍부한 지식을 바탕으로 복잡한 추론까지 수행할 수 있는 대형 언어모델만의 장점은 여전히 유효하다는 것이다.<br><br>
                MS 역시 내부적으로는 LLM과 SLM의 장점을 결합한 하이브리드 형태의 모델을 운용 중인 것으로 알려졌다. 정교한 응답이 요구되는 경우에는 LLM이, 단순하고 직관적인 태스크에는 SLM이 역할을 분담하는 식이다.<br><br>
                이처럼 단기적으로는 다양한 형태의 언어모델이 공존하는 양상이 이어질 것으로 보인다. 그러나 장기적 관점에서 Phi-3로 대표되는 경량화된 언어모델의 잠재력은 매우 크다는 것이 전문가들의 중론이다. 모델 효율화와 경량화는 인공지능 기술 발전의 필연적 방향성인 만큼, MS의 이번 행보를 신호탄으로 관련 연구가 더욱 가속화될 것으로 예상된다.<br><br>


                <a href="https://ko.root-nation.com/ua/articles-ua/tech-ua/ua-phi-3-mini/" target="_blank"> 2024년04월28일 : 마이크로소프트, 미세조정 없이 성능 개선된 'Phi-3' 언어모델 공개</a> <br>  
        </p>

        </li>
        <!-- 이곳에 더 많은 표현을 추가할 수 있습니다 -->
        </ul>


    <ul>
        <li>
        <p>
        <strong><h2></h3>구글 딥마인드, 미세조정 없이 LLM 성능 개선하는 '다중샷 ICL' 공개</h3><br><br>
                </strong>
                <img src="../../image/ai_news/ai news sub 20240428_01.png" alt="" width="100%">           
                구글 딥마인드 연구진이 대형언어모델(LLM)의 긴 컨텍스트 창을 활용해 복잡한 미세조정 없이 애플리케이션에 맞춰 모델의 성능을 개선하는 학습 기술을 공개했다. 이 기술은 프롬프트에 수백~수천 개의 훈련 사례를 적용해 LLM의 성능을 향상시키는 '다중샷 상황 내 학습(Many-shot In-Context Learning, ICL)'이다. 
                연구 결과는 온라인 아카이브에 '다중샷 상황 내 학습'이라는 제목의 논문으로 게재되었다.<br><br>
                ICL은 LLM에 해결해야 할 문제와 함께 문제 해결을 위한 응답 예제가 포함된 프롬프트를 제공하면, LLM이 예제를 보고 학습하는 방식이다. 미세조정과 달리 모델의 매개변수를 변경할 필요가 없어 사용자가 더 쉽게 접근하고 활용할 수 있다는 장점이 있다. 다만 ICL은 LLM의 컨텍스트 창에 의해 제한되는데, 예를 들어 GPT-3의 경우 약 2,000개의 토큰을 지원하는 창이 있어 프롬프트에 입력할 수 있는 예제 수가 제한된다.<br><br>
                하지만 최신 모델들은 10만 개 이상의 토큰을 지원하는 컨텍스트 창을 제공하며, 특히 구글의 제미나이 1.5 프로는 100만 개가 넘는 토큰을 지원한다. 이로 인해 각 프롬프트에 수천 개의 ICL 예제를 넣을 수 있게 되었다.<br><br>
                연구진은 다중샷 ICL이 수학 문제 해결, 질문 답변, 결과 보상 모델링, 리소스가 부족한 언어 번역, 계획 및 감정 분석 등 여러 문제 영역에서 LLM의 성능에 얼마나 영향을 미치는지 실험했다. 어떤 경우에는 하나의 프롬프트에 최대 8,192개의 ICL 예제가 포함되기도 했다.<br><br>
                실험 결과, 프롬프트에 더 많은 예제가 추가될수록 모델의 성능이 계속 향상되는 것으로 나타났다. 번역 작업에서 다중샷 ICL을 적용한 제미나이 프로는 리소스가 부족한 쿠르드어와 타밀어에 대해 새로운 최고 성능을 기록했다. 요약 작업에서도 다중샷 ICL을 적용한 제미나이 프로가 미세조정된 요약 모델과 동등한 성능을 보였다.<br><br>
                다만 다중샷 ICL은 인간이 대량의 고품질 예제를 생성해야 한다는 어려움이 있다. 연구진은 이를 해결하기 위해 LLM에게 작업에 대한 사고사슬(Chain of Thought, CoT) 프롬프트를 제공해 모델 스스로 원하는 예제를 생성하도록 했다. CoT 프롬프트는 유사한 작업을 해결하기 위한 추론 단계를 프롬프트 앞에 추가해 LLM이 원하는 작업을 위한 올바른 예제를 생성하도록 유도한다.<br><br>
                또한 연구진은 LLM이 작업 해결에 필요한 지식을 이미 보유하고 있는 경우, 프롬프트에 관련 정보를 추가해 모델이 내부 개념에 더 집중하도록 하는 방법도 도입했다. 문제에 대한 제로샷이나 퓨샷 프롬프트와 함께 해결되지 않은 문제 목록으로 프롬프트를 구성하는 식이다.<br><br>
                전문가들은 LLM의 컨텍스트 창이 커짐에 따라 미세조정 모델이나 검색 증강 생성(Retrieval-Augmented Generation, RAG)과 같은 다른 기술이 더 이상 필요하지 않을 수도 있다고 전망한다. 모델을 미세조정하거나 복잡한 검색 파이프라인을 생성하는 대신, 작업에 필요한 정보와 학습 예제 및 지침이 포함된 프롬프트를 만들면 된다는 설명이다.<br><br>
                하지만 현재로서는 다중샷 ICL과 같은 기술을 확장하기에 어려움이 있다. 수백 개의 예제로 모든 프롬프트를 늘리면 추론 속도와 비용이 폭발적으로 증가하기 때문이다.  따라서 다중샷 ICL은 LLM 애플리케이션의 탐색 및 프로토타이핑 단계에서 다양한 프롬프트 엔지니어링 기술을 시험해 볼 수 있는 유용한 도구로 평가되고 있다. 향후 토큰 소비를 줄이기 위한 노력이 필요할 것으로 보인다.<br><br>


                <a href="https://www.aitimes.com/news/articleView.html?idxno=159122" target="_blank"> 2024년04월28일 : 구글 딥마인드, 미세조정 없이 LLM 성능 개선하는 '다중샷 ICL' 공개</a> <br>  
        </p>

        </li>
        <!-- 이곳에 더 많은 표현을 추가할 수 있습니다 -->
        </ul>



    <ul>
        <li>
        <p>
        <strong><h2></h3>마이크로소프트, 규모는 작아도 성능은 더 뛰어난 새로운 소형 언어 모델 개발</h3><br><br>
                </strong>
                때로는 복잡한 문제를 해결하는 가장 좋은 방법은 동화책에서 힌트를 얻는 것이다. 이는 마이크로소프트 연구원들이 더 작은 패키지에 더 강력한 성능을 담는 방법을 고안하면서 얻은 교훈이다.<br><br>
                <img src="../../image/ai_news/phi3.jpg" alt="" width="100%">
                때로는 복잡한 문제를 해결하는 가장 좋은 방법은 동화책에서 힌트를 얻는 것이다. 이는 마이크로소프트 연구원들이 더 작은 패키지에 더 강력한 성능을 담는 방법을 고안하면서 얻은 교훈이다.<br><br>
                작년, 기계 학습의 수수께끼에 대한 잠재적 해결책을 하루 종일 고민한 후, 마이크로소프트의 로넨 엘단은 딸에게 자장가를 읽어주면서 "그녀가 이 단어를 어떻게 배웠지? 이 단어들을 어떻게 연결하는 걸까?"라고 자문했다.<br><br>
                이는 마이크로소프트 리서치의 기계 학습 전문가로 하여금 AI 모델이 4세 아동이 이해할 수 있는 단어만을 사용해서 얼마나 많이 배울 수 있을지 궁금증을 갖게 했고, 궁극적으로 더 많은 사람들이 AI를 더 쉽게 접근할 수 있도록 하는 새로운 유형의 더 유능한 소형 언어 모델을 만들어내는 혁신적인 학습 접근법으로 이어졌다.<br><br>
                대형 언어 모델(LLMs)은 AI를 사용하여 더 생산적이고 창의적일 수 있는 흥미로운 새로운 기회를 창출했다. 하지만 그 크기로 인해 작동에 상당한 컴퓨팅 자원이 필요할 수 있다.<br><br>
                마이크로소프트는 이러한 모델이 여전히 많은 유형의 복잡한 작업을 해결하는 데 있어 최고의 기준이 될 것이라는 점을 인정하면서도, LLMs에서 발견되는 많은 동일한 기능을 제공하지만 크기가 작고 더 적은 양의 데이터로 학습되는 일련의 소형 언어 모델(SLMs)을 개발해 왔다.<br><br>
                마이크로소프트는 오늘 마이크로소프트 연구원들이 개발한 학습 혁신 덕분에 언어, 코딩 및 수학 능력을 평가하는 다양한 벤치마크에서 동일 크기 및 그 다음 크기의 모델을 능가하는 가장 유능하고 비용 효율적인 소형 언어 모델인 Phi-3 제품군의 공개 모델을 발표했다.<br><br>
                마이크로소프트는 이제 그 크기가 두 배인 모델보다 성능이 우수한 38억 개의 매개변수를 측정하는 Phi-3-mini를 더 강력한 소형 언어 모델 제품군 중 첫 번째로 공개한다고 밝혔다.<br><br>
                오늘부터 Phi-3-mini는 마이크로소프트 Azure AI 모델 카탈로그와 기계 학습 모델 플랫폼인 Hugging Face, 그리고 로컬 머신에서 모델을 실행하기 위한 경량 프레임워크인 Ollama에서 사용할 수 있다. 또한 어디서나 배포할 수 있는 표준 API 인터페이스를 갖춘 NVIDIA NIM 마이크로서비스로도 제공될 예정이다.<br><br>
                마이크로소프트는 또한 품질과 비용 면에서 더 많은 선택권을 제공하기 위해 Phi-3 제품군에 추가 모델이 곧 출시될 것이라고 발표했다. Phi-3-small (70억 개의 매개변수)과 Phi-3-medium (140억 개의 매개변수)은 Azure AI 모델 카탈로그 및 기타 모델 가든에서 곧 사용할 수 있게 될 것이다.<br><br>
                소형 언어 모델은 더 단순한 작업에서 잘 수행되도록 설계되었으며, 제한된 리소스를 가진 조직에서 보다 접근하기 쉽고 사용하기 쉬우며, 특정 요구 사항에 맞게 미세 조정하기가 더 용이하다.<br><br>
                마이크로소프트의 생성형 AI 담당 수석 제품 관리자인 소날리 야다브는 "우리가 앞으로 보게 될 것은 대형에서 소형으로의 전환이 아니라, 단일 범주의 모델에서 고객이 자신의 시나리오에 가장 적합한 모델을 결정할 수 있는 능력을 갖춘 모델 포트폴리오로의 전환"이라고 말했다.<br><br>
                마이크로소프트의 AI 부사장인 루이스 바르가스는 "일부 고객은 소형 모델만 필요로 할 수 있고, 일부는 대형 모델이 필요할 것이며, 많은 고객들이 다양한 방식으로 둘을 결합하기를 원할 것"이라고 말했다.<br><br>
                적합한 언어 모델을 선택하는 것은 조직의 특정 요구 사항, 작업의 복잡성, 가용 자원에 달려 있다. 소형 언어 모델은 클라우드가 아닌 기기에서 로컬로 실행할 수 있는 애플리케이션을 구축하고자 하는 조직과 광범위한 추론이 필요하지 않거나 빠른 응답이 필요한 작업에 적합하다.<br><br>
                소형 언어 모델은 또한 고품질의 결과가 필요하지만 자체 사내에서 데이터를 보관하고자 하는 상황에 직면하는 규제 대상 산업 및 분야에 대한 잠재적 솔루션을 제공한다고 야다브는 말했다.<br><br>
                바르가스와 야다브는 클라우드에 연결되지 않은 "에지"에서 작동하는 스마트폰 및 기타 모바일 기기에 더 유능한 SLM을 배치할 수 있는 기회에 특히 흥분하고 있다. (자동차 컴퓨터, Wi-Fi가 없는 PC, 교통 시스템, 공장 현장의 스마트 센서, 원격 카메라 또는 환경 규정 준수를 모니터링하는 장치를 생각해보라.) 데이터를 기기 내에 보관함으로써 사용자는 "지연 시간을 최소화하고 개인 정보 보호를 극대화할 수 있다"고 바르가스는 말했다.<br><br>
                지연 시간은 LLM이 사용자 프롬프트에 대한 답변을 생성하는 데 사용되는 정보를 검색하기 위해 클라우드와 통신할 때 발생할 수 있는 지연을 의미한다. 경우에 따라 고품질의 답변을 기다릴 가치가 있지만, 다른 시나리오에서는 속도가 사용자 만족도에 더 중요하다.<br><br>
                SLM은 오프라인에서 작동할 수 있기 때문에 더 많은 사람들이 이전에는 불가능했던 방식으로 AI를 활용할 수 있게 될 것이라고 바르가스는 말했다.<br><br>
                예를 들어, SLM은 셀룰러 서비스가 부족한 시골 지역에서 사용될 수 있다. 작물을 검사하는 농부가 잎이나 가지에서 병의 징후를 발견한 경우를 생각해 보자. 시각적 기능을 갖춘 SLM을 사용하여 농부는 문제의 작물 사진을 찍고 해충이나 질병을 치료하는 방법에 대한 즉각적인 권장 사항을 받을 수 있다.<br><br>
                바르가스는 "좋은 네트워크가 없는 세계의 일부 지역에 있다면, 여전히 기기에서 AI 경험을 할 수 있을 것"이라고 말했다.<br><br>
                고품질 데이터의 역할<br><br>
                이름에서 알 수 있듯이 SLM은 LLM에 비해 매우 작다. 적어도 AI 기준으로는 그렇다. Phi-3-mini는 모델의 출력을 결정하는 데 도움이 되는 알고리즘 노브를 의미하는 측정 단위인 38억 개의 매개변수 "만" 가지고 있다. 반면에 가장 큰 대형 언어 모델은 그 크기가 훨씬 더 크다.<br><br>
                대형 언어 모델에 의해 이뤄진 생성형 AI의 엄청난 발전은 주로 그 절대적인 크기에 의해 가능해진 것으로 여겨져 왔다. 그러나 마이크로소프트 팀은 작은 패키지에서 엄청난 결과를 제공할 수 있는 소형 언어 모델을 개발할 수 있었다. 이 돌파구는 학습 데이터에 대한 매우 선별적인 접근 방식을 통해 가능했으며, 이는 동화책이 작용하는 부분이다.<br><br>
                지금까지 대형 언어 모델을 학습시키는 표준적인 방법은 인터넷에서 대량의 데이터를 사용하는 것이었다. 이는 언어의 뉘앙스를 이해하고 사용자 프롬프트에 대한 지능적인 답변을 생성하는 데 필요한 콘텐츠에 대한 이러한 유형의 모델의 거대한 식욕을 충족시키는 유일한 방법으로 여겨졌다. 그러나 마이크로소프트 연구원들은 다른 아이디어를 가지고 있었다.<br><br>
                마이크로소프트의 생성형 AI 연구 부사장이자 더 유능한 소형 언어 모델 개발을 주도해 온 세바스티앙 뷔벡은 "단순히 원시 웹 데이터에 대해 학습하는 대신, 극도로 높은 품질의 데이터를 찾아보는 것은 어떨까요?"라고 물었다. 그러나 어디에 초점을 맞출 것인가?<br><br>
                엘단의 딸과의 밤마다 읽기 의식에서 영감을 받은 마이크로소프트 연구원들은 명사, 동사, 형용사를 대략 동일한 수로 포함하여 3,000개의 단어로 시작하는 개별 데이터 세트를 만들기로 결정했다. 그런 다음 대형 언어 모델에 목록에서 하나의 명사, 하나의 동사, 하나의 형용사를 사용하여 어린이 이야기를 만들도록 요청했는데, 이는 며칠에 걸쳐 수백만 번 반복되어 수백만 개의 작은 어린이 이야기를 생성했다.<br><br>
                SLM은 … 작업을 완료하기 위해 클라우드로 이동할 필요가 없는 계산에 고유하게 위치합니다.<br><br>
                연구원들은 결과로 생성된 데이터 세트를 "TinyStories"라고 명명하고 이를 사용하여 약 1,000만 개의 매개변수를 가진 매우 작은 언어 모델을 학습시켰다. 놀랍게도 자체 이야기를 만들라는 요청을 받았을 때, TinyStories로 학습된 소형 언어 모델은 완벽한 문법으로 유창한 내러티브를 생성했다.<br><br>
                그 다음, 그들은 실험을 한 단계 더 높였다. 이번에는 더 큰 규모의 연구원 그룹이 교육적 가치와 콘텐츠 품질을 기준으로 필터링된 신중하게 선택된 공개 데이터를 사용하여 Phi-1을 학습시켰다. 공개적으로 사용 가능한 정보를 초기 데이터 세트로 수집한 후, TinyStories에 사용된 것과 유사한 프롬프팅 및 시딩 공식을 사용했지만 한 단계 더 나아가 더 정교하게 만들어 더 넓은 범위의 데이터를 포착할 수 있도록 했다. <br><br>
                높은 품질을 보장하기 위해 결과 콘텐츠를 반복적으로 필터링한 후 추가 합성을 위해 LLM에 다시 공급했다. 이러한 방식으로 몇 주에 걸쳐 더 유능한 SLM을 학습시키기에 충분히 큰 데이터 코퍼스를 구축했다.<br><br>
                연구원들은 이 데이터 세트를 "CodeTextbook"이라고 명명했다.<br><br>
                연구원들은 어려운 개념을 학생에게 분해하는 교사처럼 데이터 선택에 접근함으로써 데이터 세트를 더욱 향상시켰다. 뷔벡은 "교과서와 같은 자료, 매우 잘 설명하는 양질의 문서를 읽기 때문에 언어 모델이 이 자료를 읽고 이해하는 작업을 훨씬 더 쉽게 만든다"고 말했다.<br><br>
                고품질 정보와 저품질 정보를 구별하는 것은 인간에게는 어렵지 않지만, 마이크로소프트 연구원들이 SLM을 학습시키는 데 필요하다고 결정한 1테라바이트 이상의 데이터를 살펴보는 것은 LLM의 도움 없이는 불가능할 것이다.<br><br>
                마이크로소프트 리서치 AI 프론티어 랩을 이끌고 새로운 학습 접근법이 개발된 곳의 부사장인 에제 카마르는 "현재 세대의 대형 언어 모델의 힘은 합성 데이터 생성 측면에서 우리가 이전에 가지지 못했던 실제 추진력"이라고 말했다.<br><br>
                신중하게 선택된 데이터로 시작하면 모델이 원치 않거나 부적절한 응답을 반환할 가능성을 줄일 수 있지만, 모든 잠재적 안전 문제를 방지하기에는 충분하지 않다. 모든 생성형 AI 모델 출시와 마찬가지로 마이크로소프트의 제품 및 책임감 있는 AI 팀은 Phi-3 모델 개발에서 위험을 관리하고 완화하기 위해 다층적 접근 방식을 사용했다.<br><br>
                예를 들어, 초기 학습 후 모델이 이상적으로 응답해야 하는 방법에 대한 추가 예제와 피드백을 제공했는데, 이는 추가적인 안전 계층을 구축하고 모델이 고품질 결과를 생성하는 데 도움이 된다. 각 모델은 또한 평가, 테스트 및 수동 레드팀을 거치는데, 이는 전문가가 잠재적 취약점을 식별하고 해결하는 과정이다.<br><br>
                마지막으로 Phi-3 모델 제품군을 사용하는 개발자는 또한 Azure AI에서 사용할 수 있는 도구 모음을 활용하여 더 안전하고 신뢰할 수 있는 애플리케이션을 구축하는 데 도움을 받을 수 있다.<br><br>
                적절한 작업에 적합한 크기의 언어 모델 선택하기<br><br>
                그러나 고품질 데이터로 학습된 소형 언어 모델에도 한계가 있다. 이들은 LLM이 더 큰 용량과 훨씬 더 큰 데이터 세트를 사용한 학습으로 인해 뛰어난 심층 지식 검색을 위해 설계되지 않았다.<br><br>
                LLM은 크기와 처리 능력으로 인해 방대한 양의 정보에 대한 복잡한 추론에서 SLM보다 우수하다. 이는 예를 들어 방대한 과학 논문을 살펴보고, 복잡한 패턴을 분석하며, 유전자, 단백질 또는 화학 물질 간의 상호 작용을 이해하는 데 도움을 줌으로써 신약 개발과 관련될 수 있는 기능이다.<br><br>
                바르가스는 "작업이 있고, 그 작업이 충분히 복잡해서 해당 작업을 여러 하위 작업으로, 때로는 하위-하위 작업으로 분할하는 방법을 알아내야 하고, 최종 답변을 제시하기 위해 이 모든 작업을 실행해야 하는 계획과 같은 것은 당분간 대형 모델의 영역에 있을 것"이라고 말했다.<br><br>
                고객과의 지속적인 대화를 바탕으로 바르가스와 야다브는 일부 기업이 작업이 너무 복잡하지 않은 경우 일부 작업을 소형 모델로 "오프로딩"하는 것을 볼 것으로 예상한다.<br><br>
                예를 들어, 기업은 Phi-3를 사용하여 긴 문서의 주요 내용을 요약하거나 시장 조사 보고서에서 관련 통찰력과 산업 동향을 추출할 수 있다. 다른 조직은 Phi-3를 사용하여 제품 설명이나 소셜 미디어 게시물과 같은 마케팅이나 영업 팀을 위한 콘텐츠 생성에 도움을 줄 수 있다. 또는 기업이 Phi-3를 사용하여 고객의 기본적인 요금제 관련 질문이나 서비스 업그레이드에 대해 답변하는 지원 챗봇에 동력을 공급할 수 있다.<br><br>
                내부적으로 마이크로소프트는 이미 대형 언어 모델이 라우터 역할을 하는 모델 제품군을 사용하고 있는데, 더 적은 컴퓨팅 성능을 요구하는 특정 쿼리를 소형 언어 모델로 전달하는 한편, 다른 더 복잡한 요청은 스스로 처리한다.<br><br>
                "여기서 주장은 SLM이 대형 언어 모델을 대체하거나 교체할 것이라는 게 아니다"라고 카마르는 말했다. 대신 SLM은 "에지에서의 계산, 기기에서의 계산, 작업을 완료하기 위해 클라우드로 이동할 필요가 없는 계산에 고유하게 위치한다. 그렇기 때문에 이 모델 포트폴리오의 장단점을 이해하는 것이 우리에게 중요하다"라고 설명했다.<br><br>
                그리고 크기는 중요한 장점을 지닌다. 소형 언어 모델과 클라우드의 대형 모델에서 얻을 수 있는 지능 수준 사이에는 여전히 차이가 있다고 뷔벡은 말했다. "그리고 아마도 항상 차이가 있을 것이다. 대형 모델도 계속 진전을 이룰 것이기 때문이다."<br><br>
                <a href="https://news.microsoft.com/source/features/ai/the-phi-3-small-language-models-with-big-potential/" target="_blank"> 2024년04월25일 : MICROSOFT Tiny but mighty: The Phi-3 small language models with big potential</a> <br>  
        </p>

        </li>
        <!-- 이곳에 더 많은 표현을 추가할 수 있습니다 -->
        </ul>

    <ul>
        <li>
        <p>
        <h3>생성형 AI에서 빠진 조각, RAG가 완성한다</h3><br><br>
                
                전 세계의 주목을 받으며 등장한 생성형 AI를 기업에서 구현하는 과정은 시행착오의 연속이었다. AI 채팅 도구가 일상적 업무에 활용되면서 기업 내 섀도우 AI 사용률이 급증하고 있지만, 지식 집약적 워크플로우 방면에서 생성형 AI는 아직 업무 방식을 혁신한다는 원대한 약속을 이행하지 못하고 있다.<br><br>
                <img src="../../image/ai_news/RAG1.jpg" alt="" width="100%">
                그러나 검색 증강 생성(RAG)이라는 프로세스 덕분에 이러한 환멸의 시기가 오래 지속되지는 않을 것으로 보인다. RAG는 과거에는 불가능했던 기업 내 생성형 AI 사용례를 만들어내고 있으며, 오픈AI, 마이크로소프트, 메타, 구글, 아마존과 많은 AI 신생업체들이 엔터프라이즈 중심의 RAG 기반 솔루션을 공격적으로 출시하고 있다.<br><br>
                RAG는 기업에서 생성형 AI의 발목을 잡고 있던 한 가지 큰 문제, 즉 정보 검색 모델을 해결한다. 이제 생성형 AI 도구는 대형 언어 모델(LLM)이 학습한 데이터 외의 관련 데이터에 액세스할 수 있는 방법을 갖게 되었으며, 해당 정보를 기반으로 결과물을 생성할 수 있게 되었다. 단순해 보이지만 이는 기업 사용례에서 생성형 AI 도구의 잠재력을 발휘하는 핵심 기능이다.<br><br>
                생성형 AI가 학습 데이터 외부의 정보에 액세스할 수 없을 때 발생하는 문제를 살펴보면, 챗GPT와 같은 생성형 AI 도구는 LLM을 기반으로 하는데, 이는 특정 시점에 수집된 제한된 범위의 데이터로 학습되어 도메인별 또는 최신 데이터가 부족하다는 한계가 있다. 또한 LLM은 학습한 언어 패턴을 기반으로 새로운 정보를 생성하면서 신뢰할 수 있는 것처럼 보이는 사실을 만들어내는 환각 문제가 있어, 정확성이 중요한 엔터프라이즈 워크플로우에서 걸림돌로 작용하고 있다.<br><br>
                기업에서 필요로 하는 생성형 AI는 첫째, 모든 관련 최신 도메인별 데이터를 포함하여 포괄적이고 시의적절해야 하고, 둘째, 결과물에 사용된 모든 출처를 인용하여 신뢰할 수 있고 투명해야 하며, 셋째, LLM 학습 데이터가 아닌 신뢰할 수 있는 특정 데이터 세트에 기반하여 정확해야 한다.<br><br>
                RAG는 이러한 요구사항을 충족시킬 수 있다. RAG 기반 시스템은 검색 기반 모델과 생성 모델을 통합하여, 대량의 불완전한 비정형 데이터에서 정확한 요약과 인사이트를 추출해 자연어로 명확하고 정확하게 제시하는 지식 집약적인 워크플로우를 처리할 수 있다.<br><br>
                RAG의 4가지 단계는 다음과 같다. 첫째, 신뢰할 수 있는 소스에서 관련 텍스트 정보를 시스템이 분류에 사용할 수 있는 특수 코드로 변환하는 벡터화, 둘째, 수학적 표현을 사용하여 쿼리를 신뢰할 수 있는 정보 소스에 포함된 유사한 코드와 일치시키는 검색, 셋째, 질문 내용, 사용자, 정보 출처를 고려하여 가장 유용한 정보를 선택하는 순위 매기기, 넷째, 해당 문서에서 가장 관련성이 높은 부분을 질문과 결합하여 LLM에 공급하여 결과물을 생성하는 생성 단계이다.<br><br>
                RAG 기반 생성형 AI 도구는 기초 데이터를 적절히 소싱하고 검증하는 한, LLM에만 의존하는 도구보다 훨씬 더 정확하고 포괄적이며 관련성 높은 결과물을 생성할 수 있다. 기업 사용자도 출력된 결과를 신뢰하고 중요한 워크플로우에 활용할 수 있을 것이다.<br><br>
                이에 오픈AI는 챗GPT에 RAG 기능을 도입하기 시작했고, 퍼플렉시티 AI 같은 최신 검색 도구는 원전을 인용하는 응답으로 인기를 얻고 있다. 그러나 여전히 도메인별 엔터프라이즈 사용례에 맞게 작동하려면 시간과 투자가 더 필요한 상황이다.<br><br>
                기업용으로 준비한다는 것은 기초 데이터를 도메인별로 소싱 및 조사하고, 검색을 사용자 정의하며, 사용례와 가장 관련성이 높은 문서를 반환하도록 검색 순위를 매기고, 출력에 올바른 용어, 어조 및 형식을 사용하도록 LLM을 미세 조정하는 것을 의미한다.<br><br>
                생성형 AI에 대한 초기의 뜨거운 관심에도 불구하고, 지금까지 기업에서의 실제 도입은 저조했다. 그러나 RAG는 정확성, 신뢰성, 도메인 특이성이 요구되는 분야에서 생성형 AI 솔루션을 제공함으로써 산업 전반의 판도를 바꾸고 있다. RAG의 등장으로 엔터프라이즈에서 생성형 AI 실현의 새로운 기회가 열리고 있는 것이다.<br><br>
                <a href="https://www.itworld.co.kr/news/334800" target="_blank"> 2024년04월25일 : ITWORLD 생성형 AI에서 빠진 조각, RAG가 완성한다</a> <br>  
        </p>

        </li>
        <!-- 이곳에 더 많은 표현을 추가할 수 있습니다 -->
        </ul>


    <ul>
        <li>
        <p>
        <strong>
                </strong>
                <h3>'토큰 3조개' 익힌 텐센트 AI, 챗GPT보다 학습속도 빨라</h3><br><br>
                
                중국 최대 정보기술(IT) 기업인 텐센트가 개발한 인공지능(AI) 대규모언어모델(LLM) '훈위안'이 최근 학습한 토큰(말뭉치) 수가 3조 개에 달한다는 사실이 알려졌다. 이는 지난해 9월 훈위안 첫 공개 당시 밝힌 2조 개에서 불과 7개월 만에 50%나 증가한 수치다. 이는 네이버가 2021년 선보인 한국 최초 LLM의 5600억 토큰과 비교해도 압도적인 규모로, '챗GPT의 아버지'로 불리는 샘 올트먼의 오픈AI가 2020년 GPT3 출범 당시 투입한 3000억 개 토큰과 비교해도 훨씬 빠른 속도다. 텐센트의 이러한 빠른 추격에 세계 빅테크들이 경계심을 갖는 이유다.<br><br>
                텐센트가 AI 개발에 본격적으로 뛰어든 것은 2016년으로 거슬러 올라간다. 당시 텐센트는 텐센트AI랩을 설립하고, 자사의 SNS인 위챗과 웨이신을 통해 축적한 방대한 데이터를 AI 학습에 활용하기 시작했다. 지난 18일 방문한 중국 광저우 위챗·웨이신 사무동에 따르면, 현재 이 두 SNS의 이용자 수는 14억 4700만 명에 달한다. 이 중 중국인 이용자가 13억 5900만 명으로 거의 모든 중국인이 사용하고 있으며, 외국인 이용자도 1억 명에 육박한다. 텐센트 관계자는 "대다수 AI 기업이 토큰에 쓸 데이터 부족으로 어려움을 겪고 있지만, 텐센트는 걱정할 필요가 없다"고 말했다. 위챗이 금융 거래부터 진료 예약, 처방전 발송, 식당 결제, 택시 콜, 공유자전거 이용 등 일상생활 전반에 활용되는 '생활 리모컨' 역할을 하기 때문에 AI 학습에 필요한 토큰을 대량으로 확보할 수 있기 때문이다.<br><br>
                AI 성능 개선에 있어 토큰은 가장 확실한 수단으로 꼽힌다. 아무리 최첨단 AI 칩을 사용한다 해도 학습에 투입되는 데이터가 부족하다면 성능 향상에 한계가 있기 마련이다. 반면 칩의 성능이 다소 떨어지더라도 방대한 데이터를 학습한다면 더 나은 결과를 기대할 수 있다. 네이버 관계자는 "오프라인의 실시간 데이터를 대규모로 확보하는 곳은 중국 빅테크뿐"이라고 말했다.<br><br>
                텐센트의 마화텅 회장은 훈위안을 고도화하는 한편, 기업AI로 사업 영역을 확장하고 있다. 그는 최근 임직원에게 보낸 메시지에서 "훈위안은 수치 추론, 논리적 추론, 다단계 대화 등에서 탁월한 성능을 발휘하는 최상위 모델"이라고 강조했다. 훈위안은 이미지 생성, 텍스트 인식, 카피라이팅 등 다양한 기능을 지원하며, SNS, 금융, 공공 서비스, 전자상거래, 물류 운송, 게임 등 주요 산업에서 활용도가 높다. 다우슨 퉁 텐센트 수석부사장은 "금융, 교육, 물류, 게임 등 20개 산업군에 걸쳐 50여 개 솔루션을 보유한 기업용 훈위안 서비스를 중국 기업에 제공하고 있다"며 "각 기업에 최적화된 지능형 서비스를 선보일 것"이라고 말했다.<br><br>
                기업AI는 그동안 중국의 최대 약점으로 꼽혀왔다. 소비 영역과 달리 중국 기업이 자체적으로 축적한 '정형화된 데이터'가 부족했기 때문이다. 텐센트는 자사의 AI 클라우드를 통해 주요 산업의 데이터를 끌어모음으로써 이러한 약점을 극복하겠다는 계획이다. 구글, 아마존, 마이크로소프트 등이 주도하는 초거대 AI 생태계와는 완전히 다른, 별개의 'AI 행성'을 만들겠다는 것이 마화텅 회장의 전략이다. 실제로 텐센트는 지난달 자체 개발한 생성형 AI 게임엔진 '지넥스'를 공개하며 이에 대한 의지를 내비쳤다. 생성형 AI를 활용해 콘텐츠 제작 시간을 단축하고 풍성한 게임 스토리를 만들어낼 수 있는 혁신적인 도구인 셈이다. 텐센트는 현재 훈위안의 기업AI를 자사의 사업 및 서비스에 적용 중인데, 그 분야만 해도 400개에 달한다고 한다.<br><br>
                텐센트는 AI 기술을 바탕으로 글로벌 시장 공략에도 적극적으로 나서고 있다. 2016년 아시아, 유럽, 미국을 아우르는 글로벌 파트너 네트워크를 구축한 것을 시작으로 해외 진출을 본격화했으며, 최근에는 중남미와 중동 지역에서 독자적인 생태계를 구축하는 중이다. 자오젠난 텐센트 클라우드인터내셔널 부사장은 "클라우드, AI, 빅데이터, 보안 등 주요 기술을 통합해 맞춤형 디지털 솔루션을 구축해주는 형태의 글로벌 사업을 키워나갈 것"이라고 밝혔다. 이를 위해 텐센트는 지난해에만 640억 위안(약 12조 원)을 연구개발(R&D)에 투자했는데, 이는 역대 최대 규모다. 올해는 R&D 투자금 중 AI 관련 비중을 더욱 높일 것으로 알려졌다.<br><br>
                중국 IT 공룡 텐센트의 야심찬 행보가 주목되는 이유다. 자국 내 시장에서의 독보적인 지위를 바탕으로 축적한 데이터와 AI 기술력을 앞세워 글로벌 무대에서도 존재감을 과시하겠다는 전략이 엿보인다. 구글, 아마존, 마이크로소프트 등 미국 빅테크 기업들이 주도하는 AI 시장에서 새로운 강자로 부상할 수 있을지 귀추가 주목된다. 다만 중국 정부의 규제와 검열, 데이터 보안 문제 등은 여전히 텐센트가 넘어야 할 과제로 남아있다. 글로벌 시장에서 통할 수 있는 보편적인 가치와 기준을 충족시키는 것도 중요한 숙제다. 텐센트의 행보가 중국 IT 기업의 새로운 가능성을 보여줄 수 있을지, 아니면 자국 시장에 갇힌 한계를 노출할 지 지켜볼 일이다.<br><br>
                <a href="https://www.hankyung.com/article/2024042159721" target="_blank"> 2024년04월21일 : 한국경제 '토큰 3조개' 익힌 텐센트 AI, 챗GPT보다 학습속도 빨라  </a> <br>  
        </p>

        </li>
        <!-- 이곳에 더 많은 표현을 추가할 수 있습니다 -->
        </ul>

    <ul>
        <li>
        <p>
        <strong>
                </strong>
                <h3>“억대 연봉 옛말 됐다”…이 직원 4명분 AI가 도맡아 ‘대규모 칼바람’</h3><br><br>
                인공지능(AI)이 IT 개발자들의 핵심 업무인 코딩을 중급 이상으로 수행할 수 있게 되면서, 기업들은 고연봉 IT 개발자 대신 비용 효율적인 AI에 투자하는 추세로 바뀌고 있습니다. 이로 인해 IT 개발자들의 입지가 흔들리고 있는 상황입니다.<br><br>
                최근 전 세계 기업들은 IT 인재 영입에 들일 자금을 자체 AI 개발에 투자하고 있습니다. 구글, 마이크로소프트, 아마존 등 해외 빅테크 기업들은 대규모 구조조정을 단행하고, 절감된 비용을 AI 개발에 투자하고 있습니다. 구글은 370억 달러(약 51조 원)를, 마이크로소프트는 25억 파운드(약 4조 원)를, 아마존은 40억 달러(약 5조 원)와 1억 달러(약 1,385억 원)를 각각 AI 관련 분야에 투자할 계획입니다.<br><br>
                전문가들은 AI가 머지않아 IT 개발자의 직무를 대체할 수 있을 것으로 전망하고 있습니다. 엔비디아 CEO 젠슨 황은 AI의 발전으로 코딩 전문 직업이 사라질 수 있다고 언급했으며, 서울여대 김명주 교수는 AI를 코딩에 적용하면 효율성이 30~40% 향상될 수 있다고 설명했습니다. 아크 인베스트는 AI가 코딩 생산성을 10배 높일 수 있다고 관측했습니다.<br><br>
                국내에서도 AI로 인한 IT 개발자 일자리 대체 우려가 확산되고 있습니다. 원티드랩의 설문조사 결과, 응답자의 83.6%가 AI가 개발자 업무를 대체할 것이라고 답했습니다. 실제로 국내 IT 개발자 채용은 감소 추세를 보이고 있으며, 사람인의 분석에 따르면 지난해 IT 개발·데이터 직무 공고가 전년 대비 7.4% 감소했습니다.<br><br>
                국내 대형 IT 기업들도 연봉 및 인센티브 인상률을 낮추고, AI에 투자를 집중하고 있습니다. 네이버와 카카오의 직원 평균 연봉은 각각 11.5%, 27.3% 감소했으며, 이는 AI 투자를 늘리기 위한 조치로 보입니다.<br><br>
                전문가들은 기업들이 AI의 효율성을 확인하게 되면, 뛰어난 인재를 제외하고는 새로운 개발자 채용을 줄일 가능성이 높다고 예측합니다. AI의 발전이 IT 개발자의 일자리에 상당한 영향을 미칠 것으로 보이며, 이에 따른 고용 구조의 변화가 예상됩니다.<br><br>
                IT 업계에서는 신입 개발자 채용을 지양하고, 검증된 경력자 위주로 선발하는 추세입니다. 프로젝트성 수시 채용만 운영하는 등 채용 규모 자체를 줄이고 있는 상황입니다.<br><br>
                AI의 발전과 기업들의 투자 전략 변화로 인해, IT 개발자들의 고용 환경이 급변하고 있습니다. 단순 코딩 업무는 AI로 대체되고, 개발자들은 AI를 활용하고 관리하는 역할로 전환될 것으로 보입니다. 이러한 변화에 대응하기 위해서는 개발자들의 역량 강화와 함께, 기업과 정부 차원의 고용 안정 대책 마련이 필요할 것으로 사료됩니다.<br><br>
                <a href="https://m.mk.co.kr/amp/10992831" target="_blank"> 2024년04월17일 : 매일경제 “억대 연봉 옛말 됐다”…이 직원 4명분 AI가 도맡아 ‘대규모 칼바람’  </a> <br>  
        </p>

        </li>
        <!-- 이곳에 더 많은 표현을 추가할 수 있습니다 -->
        </ul>

        <ul>
        <li>
        <p>
        <strong>
                </strong>
                <h3>2024년 가장 많이 사용되는 AI 플랫폼 20개는..</h3><br><br>
                2024년 가장 많이 사용되는 인공지능(AI) 플랫폼 순위가 발표되었습니다. 미국 투자 전문매체 인사이더몽키가 인터넷 상의 10개 이상 순위 사이트를 참고하여, 50% 이상 등장한 플랫폼을 선정하고 지난 28일간의 총 사이트 방문수를 기준으로 순위를 매겼습니다. 웹사이트가 없는 플랫폼의 경우에는 총 구독자 수나 사용자 수를 기준으로 하였습니다.<br><br>
                1위는 오픈AI의 챗GPT가 차지했습니다. 방문수 16억 1,000만 건으로 압도적인 성적을 기록했습니다. 2위는 구글의 제미나이가 3억 9,120만 건으로 뒤를 이었고, 3위는 의외로 번역 AI인 딥엘(DeepL)이 2억 4,130만 건으로 차지했습니다.<br><br>
                4위부터 10위까지는 캐릭터닷AI의 챗봇, 퍼플렉시티 AI의 AI 기반 검색엔진, 앤트로픽의 클로드, 쿼라의 AI 챗봇 포, 마이크로소프트(MS)의 코파일럿, AI 언어모델인 다이얼로GPT, AI 기반 검색엔진 유챗이 각각 자리를 잡았습니다.<br><br>
                톱10 중에서 대형언어모델(LLM)이나 AI 챗봇을 기반으로 하지 않은 플랫폼은 번역 AI인 딥엘이 유일했습니다. MS가 8위에 오른 것은 예상 밖의 결과였으며, 퍼플렉시티 AI와 유챗 등 AI 기반 검색 엔진의 상승세도 주목할 만한 점이었습니다.<br><br>
                11위부터 20위까지는 AI 기반 회의 도우미 오터(Otter), 학생들의 숙제 도우미 소크라틱, 글쓰기 지원 AI 힉스.AI, 라이트소닉, 카피AI, AI 챗봇 재스퍼, 영어 음성 도우미 엘사, 코딩 도우미 깃허브의 코파일럿, 코디엄, 탭나인 등이 차지했습니다.<br><br>
                이번 순위는 AI 플랫폼의 대중적 인기와 사용 현황을 잘 보여주고 있습니다. 챗GPT와 같은 대화형 AI 모델의 폭발적인 인기가 두드러지는 가운데, 번역, 검색, 회의, 학습, 글쓰기, 코딩 등 다양한 분야에서 AI 기술이 적용되고 있음을 알 수 있습니다.<br><br>
                특히 대형 IT 기업들의 AI 플랫폼뿐만 아니라, 스타트업과 특화된 AI 서비스들도 상위권에 포진해 있어, AI 산업의 다양성과 경쟁 구도를 엿볼 수 있습니다. 퍼플렉시티 AI나 유챗 등 신생 AI 검색엔진의 약진도 눈에 띕니다.<br><br>
                AI 기술의 발전과 대중화가 가속화되면서, 이러한 AI 플랫폼들은 우리의 일상과 업무 방식에 점점 더 큰 영향을 미칠 것으로 보입니다. 동시에 AI 윤리, 프라이버시, 일자리 등 사회적 이슈에 대한 논의도 더욱 중요해질 전망입니다.<br><br>
                2024년 AI 플랫폼 순위는 급변하는 AI 기술 생태계의 현주소를 보여주는 동시에, 앞으로의 발전 방향을 가늠해볼 수 있는 흥미로운 자료라 할 수 있겠습니다. AI 기술이 가져올 변화와 기회, 그리고 우리 사회가 준비해야 할 과제들을 생각해 볼 수 있는 계기가 될 것 같습니다. <br><br>
                <a href="https://www.aitimes.com/news/articleView.html?idxno=158780" target="_blank">2024년04월14일 : AI Times 2024년 가장 많이 사용되는 AI 플랫폼 20개는 </a> <br>
        </p>

        </li>
        <!-- 이곳에 더 많은 표현을 추가할 수 있습니다 -->
        </ul>

        <ul>
            <li>
            <p>
            <strong>
                    </strong>
                    <h3>"GPT-4 다시 게을러져...클로드 3로 갈아타자" 여론 확산</h3><br><br>
                오픈AI의 챗봇 GPT-4에서 '게으름(laziness)' 문제가 다시 불거지면서, 사용자들 사이에서는 앤트로픽의 경쟁 모델인 '클로드 3'로 갈아타자는 여론이 확산되고 있습니다.
                GPT-4의 게으름 문제는 챗봇이 응답을 거부하거나 정상적으로 작동하지 않는 현상을 의미합니다. 이 문제는 지난해 여름부터 발생했으며, 당시에는 모델 분할 과정인 '전문가 모델(MoE)' 방식 적용으로 인한 일시적 성능 저하로 여겨졌습니다. 그러나 문제가 반복되자 오픈AI는 작년 11월 GPT-4 터보를 출시하여 해결을 시도했습니다.<br><br>
                올해 초에도 유사한 문제가 발생했고, 샘 알트먼 오픈AI CEO가 트위터를 통해 이를 인정하고 수정했다고 밝혔지만, 최근 다시 문제가 불거졌습니다. 사용자들은 개발자 포럼과 SNS 등을 통해 모델의 성능 저하와 불완전한 코드 생성 등에 대한 불만을 토로하고 있습니다.<br><br>
                과거에는 사용자들이 이를 그대로 감수해야 했지만, 이제는 앤트로픽의 '클로드 3'라는 대안이 등장했습니다. 클로드 3는 벤치마크 결과와 인간 선호도 평가에서 GPT-4를 능가하는 성능을 보여주고 있습니다. 엔젤 투자자 앨리 밀러는 대부분의 사람들이 클로드 3를 사용하고 있다고 언급했으며, 이던 몰릭 와튼대학교 교수는 구체적인 사례를 들어 클로드 3의 우수성을 강조했습니다.<br><br>
                오픈AI가 이 문제에 적절히 대응할 수 있을지에 대해서도 의문이 제기되고 있습니다. 밀러는 오픈AI가 다음 모델 개발에 초점을 맞추고 있어 이 문제에 충분한 자원을 투입하지 않을 것으로 예상했습니다. 실제로 최근 보도에 따르면 오픈AI는 올 여름 GPT-5 출시를 계획하고 있습니다.<br><br>
                이번 사태는 AI 챗봇 시장에서 경쟁이 심화되고 있음을 보여줍니다. GPT-4의 게으름 문제가 지속될 경우, 사용자들의 이탈이 가속화되고 클로드 3와 같은 경쟁 모델의 점유율이 확대될 가능성이 있습니다. 오픈AI가 이 문제를 신속하고 효과적으로 해결하지 않는다면, 시장에서의 위상이 흔들릴 수 있다는 우려도 제기됩니다.<br><br>
                한편, 이번 사례는 AI 기술의 발전과 상용화 과정에서 발생할 수 있는 다양한 기술적, 사회적 이슈를 보여주고 있습니다. 챗봇의 성능과 안정성, 사용자 경험, 기업의 대응 능력 등이 중요한 화두로 떠오르고 있으며, 이는 향후 AI 산업의 발전 방향과 속도에 영향을 미칠 것으로 보입니다. AI 기술을 둘러싼 경쟁과 혁신이 가속화되는 가운데, 사용자들의 요구와 기대에 부응하는 서비스를 제공하는 것이 기업들의 핵심 과제로 부상하고 있습니다.<br><br>
                    <a href="https://www.aitimes.com/news/articleView.html?idxno=158387" target="_blank">2024년03월29일 : AI Times "GPT-4 다시 게을러져...클로드 3로 갈아타자" 여론 확산 </a> <br>
            </p>
    
            </li>
            <!-- 이곳에 더 많은 표현을 추가할 수 있습니다 -->
            </ul>

            <ul>
                <li>
                <p>
                <strong>
                        </strong>
                        <h3>'트랜스포머' 보완할 기술 잇달아 공개…”메모리·시간 축소”</h3><br><br>
                구글이 입력 데이터가 커질수록 추론 속도가 느려지고 많은 메모리 공간을 필요로 하는 '트랜스포머' 아키텍처의 단점을 보완하기 위한 새로운 기술들을 잇달아 공개했습니다. 이는 '어텐션 메커니즘'이 발표된 지 7년 만에 이를 뛰어넘기 위한 시도가 본격화되고 있음을 보여줍니다.<br><br>
                구글은 먼저 대형언어모델(LLM)의 컨텍스트 창 길이를 무한 확장할 수 있는 '인피니-어텐션(Infini-attention)' 기술에 관한 논문을 온라인 아카이브에 게재했습니다. '챗GPT'나 '제미나이' 등 LLM에 사용되는 트랜스포머 아키텍처는 컨텍스트 창이 커짐에 따라 필요한 메모리와 계산 시간이 기하급수적으로 증가하는 단점이 있습니다. 예를 들어, 입력 크기를 토큰 1000개에서 2000개로 확장하면 입력을 처리하는 데 필요한 메모리와 계산 시간이 두 배가 아닌 네 배로 늘어나게 됩니다. 이는 텍스트 내 토큰들의 상관관계를 밝혀내기 위해 입력 정보를 병렬로 처리하는 '어텐션 메커니즘' 때문입니다.<br><br>
                이 문제를 해결하기 위해 구글은 메모리 및 컴퓨팅 요구 사항을 일정하게 유지하면서 LLM이 무한 길이의 텍스트를 처리할 수 있도록 인피니-어텐션 기술을 도입했습니다. 인피니-어텐션은 일반적인 어텐션 메커니즘에 '압축 메모리'를 통합하여, 입력이 컨텍스트 길이를 초과하면 모델이 계산 효율성을 위해 압축 메모리에 이전 어텐션 상태를 저장합니다. 전체 컨텍스트 기록을 유지하기 위해 다음 컨텍스트 길이를 처리할 때 이전 컨텍스트의 어텐션 상태를 버리지 않고 압축 메모리에 저장한다는 설명입니다.<br><br>
                구글에 따르면 인피니-어텐션을 적용한 LLM은 메모리 추가 없이도 100만 개 이상의 토큰 품질을 유지할 수 있습니다. 연구진은 트랜스포머 아키텍처의 어텐션 메커니즘에 대한 미묘하지만 중요한 수정을 통해 기존 LLM을 무한히 긴 컨텍스트로 자연스럽게 확장할 수 있다고 설명했습니다. 또한, 인피니-어텐션이 매우 긴 컨텍스트에 대한 모델의 일관성을 측정하는 퍼플렉시티(Perplexity) 벤치마크에서 114배 더 적은 메모리를 사용하고도 다른 긴 컨텍스트 트랜스포머 기반 LLM을 능가하는 성능을 기록했다고 주장했습니다.<br><br>
                무한한 컨텍스트 길이를 지원하는 LLM을 사용하면 이론적으로 모든 문서를 프롬프트에 삽입하고 모델이 각 쿼리에 대해 가장 관련성이 높은 답변을 선택하도록 할 수 있습니다. 또한, 특정 작업에 대한 성능을 향상하기 위해 모델을 세부적으로 조정할 필요 없이 긴 예제를 제공해 모델을 사용자 정의할 수도 있습니다.<br><br>
                더불어 구글은 엣지 장치용 오픈 소스 소형언어모델(sLM) '리커런트젬마(RecurrentGemma)'에 관한 논문도 온라인 아카이브에 게재했습니다. 이 모델 역시 트랜스포머 아키텍처의 어텐션 메커니즘을 보완한 LLM과 동등한 수준의 성능을 유지하면서 메모리 및 처리 요구 사항을 대폭 축소한다는 내용입니다.<br><br>
                트랜스포머는 입력 데이터를 모두 병렬로 처리하는 어텐션 메커니즘 때문에 데이터 볼륨이 증가함에 따라 메모리와 처리량이 크게 증가하는 약점이 있습니다. 이로 인해 LLM은 스마트폰이나 사물인터넷(IoT), 개인용 컴퓨터와 같이 리소스가 제한된 장치에 배포하기 어렵고, 데이터센터 내의 원격 서버에서 실행되기 때문에 실시간 응답을 요구하는 AI 애플리케이션에 적합하지 않습니다.<br><br>
                반면 리커런트젬마는 트랜스포머 기반 모델처럼 모든 정보를 병렬로 처리하는 대신, 주어진 시간에 입력 데이터에 집중하여 처리하는 '로컬 어텐션 메커니즘'을 도입했습니다. 이로 인해 성능을 크게 저하시키지 않으면서 계산 부하를 줄이고 처리 속도를 높입니다. 리소스가 제한된 엣지 장치에 배포하는 데 적합하고 원격 서버에서 실행할 필요가 없어 실시간 엣지 어플리케이션에 적합하다는 설명입니다.<br><br>
                리커런트젬마는 새로운 입력 데이터가 처리될 때 업데이트되는 '히든 스테이트(hidden state)'를 유지함으로써 이전 정보를 순차적으로 기억하는 순환 신경망(RNN)의 기본 구성 요소인 선형 반복(linear recurrence)을 어텐션과 결합하여, 입력 데이터에 관계없이 일정한 수준의 리소스 사용량을 유지하면서 확장된 텍스트를 처리할 수 있습니다. 특히 리커런트젬마는 처리 범위를 줄임으로써 대용량 데이터를 지속적으로 재처리하기 위한 GPU 필요성을 최소화합니다.<br><br>
                하드웨어 요구 사항이 낮아짐에 따라 리커런트젬마와 같은 모델은 일반적으로 초대형 클라우드를 위해 설계된 서버보다 컴퓨팅 전력이 적은 엣지 컴퓨팅 응용 프로그램에 더 적합합니다. 이는 클라우드 연결에 의존하지 않고 스마트폰, IoT 장치 또는 임베디드 시스템과 같은 엣지 장치에 직접 언어모델을 실행할 수 있게 합니다.<br><br>
                구글이 공개한 인피니-어텐션과 리커런트젬마는 트랜스포머 아키텍처의 한계를 극복하고 LLM의 활용 범위를 확장하는 데 기여할 것으로 보입니다. 인피니-어텐션은 무한한 길이의 컨텍스트를 처리할 수 있어 LLM의 응용 분야를 넓히고, 리커런트젠마는 엣지 장치에서 실시간으로 동작 가능한 소형 모델을 제공함으로써 AI 기술의 대중화에 기여할 것으로 기대됩니다.<br><br>
                이러한 기술 혁신은 AI 분야의 경쟁이 얼마나 치열한지를 보여주는 동시에, 트랜스포머 아키텍처의 한계를 극복하기 위한 다양한 시도가 이루어지고 있음을 시사합니다. 앞으로도 AI 기술의 발전을 위해 새로운 아이디어와 접근 방식이 등장할 것으로 예상되며, 이를 통해 AI 기술의 성능과 활용 범위가 더욱 확대될 것으로 전망됩니다.<br><br>
                        <a href="https://www.aitimes.com/news/articleView.html?idxno=158799" target="_blank">2024년03월14일 : AI Times 구글, '트랜스포머' 보완할 기술 잇달아 공개…”메모리·시간 축소” </a> <br><br>
                </p>
        
                </li>
                <!-- 이곳에 더 많은 표현을 추가할 수 있습니다 -->
                </ul>

                <ul>
                    <li>
                    <p>
                    <strong>
                            </strong>
                            <h3>기사 스토리 입력하면 웹툰 만들어주는 생성 AI 출시</h3><br>
                            미국 스타트업 로어 머신(Lore Machine)이 장문의 스토리를 입력하면, 이에 맞춰 다양한 스타일의 이미지나 사운드, 애니메이션을 생성해 웹툰이나 그래픽노블을 만들어 주는 인공지능(AI) 도구를 출시했다.<br><br>
                <img src="../../image/ai_news/ai news sub 20240306_01 lore machine.png" alt="" width="100%">
                로어 머신은 특히 '일관성 유지'를 이 도구의 가장 큰 장점으로 꼽았다.<br><br>
                로이터와 MIT 테크 리뷰 등은 5일(현지시간) 로어 머신이 AI 시각적 스토리텔링 플랫폼을 공개하고, 월 10 ~ 160달러(약 1만3400원 ~ 21만3800원)의 요금제를 내놓았으며, 현재 투자 유치를 진행 중이라고 보도했다.<br><br>
                이 도구는 텍스트 프롬프트에 단편 소설이나 대본 등 최대 3만 단어를 입력하면, 일관성 있는 이미지를 생성해 웹툰 등을 제작할 수 있다. 월 10달러를 지불하면 10만 단어를 업로드해 이미지 80개를 만들 수 있고, 가장 비싼 160달러 요금제는 224만 단어로 1792개의 이미지를 생성해 낸다.<br><br>
                생성되는 이미지는 북미식 카툰부터 일본식 만화, 수채화, 실사형 등으로 다양하게 커스터마이징할 수 있다. 사용자는 스토리보드에 따라 장면을 선택하고 생성해 작품을 완성하게 된다. 이 도구로 만화 한편을 제작하는 데 클릭 열번도 걸리지 않았다는 체험기도 있다.<br><br>
                토비 캠피언 로어 머신 설립자는 크리에이티브 에이전시 모던 아츠의 잭 라이더 설립자로부터 단편 영화 대본을 받은 뒤, 하룻밤 사이에 16페이지 분량의 그래픽 노블을 만들어냈다고 밝혔다.<br><br>
                이를 확인한 라이더 설립자는 "이미지 생성 자체가 핵심이 아니다. 서사부터 등장인물의 감정 묘사까지 모든 것이 스토리텔링에 딱 맞아떨어지는 것이 중요하다"라며 만족감을 표했다. 모던 아츠는 현재 이 도구를 활용해 넷플릭스 인기 애니메이션 '러브, 데스+로봇'의 만화 시리즈를 개발하고 있는 것으로 알려졌다.<br><br>
                로어 머신 개발은 캠피언 설립자가 미드저니를 이용해 코믹북을 제작하던 경험에서 비롯됐다. 이미지 퀄리티는 뛰어나지만, 이미지 간 일관성을 유지하기 어렵다는 문제점을 발견한 것이다. 예를 들면 주인공의 헤어 스타일이 들쭉날쭉해지거나, 특정 스타일을 고정하는 것이 거의 불가능했다.<br><br>
                이에 로어 머신이 개발한 도구의 최대 장점은 일관성 유지에 있다. 이미지 생성에는 스테이블 디퓨전을 활용하고 있으며, 자체 개발한 언어모델도 내장하고 있다. 개발에는 1년이 소요됐다. 폭력적이거나 혐오스러운 이미지 생성은 막았지만, 다른 AI 도구들처럼 환각을 100% 차단하기는 어렵다고 전했다.<br><br>
                로어 머신은 이미 중국의 컴퓨터 업체 광고 제작에 활용되는 등 지난 분기부터 상당한 수익을 거두고 있다고 밝혔다. 현재 20개의 소프트웨어 플랫폼 및 콘텐츠 업체와 파트너십을 논의 중이며, 기업이 자체 스타일로 모델을 교육할 수 있는 플랫폼 버전도 개발하고 있다. 향후에는 단어 입력 제한을 50만개까지 늘릴 계획이다.<br><br>
                로어 머신은 상업적 활용뿐만 아니라 교육 용도로도 많은 요청을 받고 있다고 전했다. 현재 투자 유치를 진행 중이지만, 구체적인 내용은 공개하지 않았다.<br><br>
                        <a href="https://www.aitimes.com/news/articleView.html?idxno=157726" target="_blank"> AI Times 기사 스토리 입력하면 웹툰 만들어주는 생성 AI 출시  </a> <br>  
                        <!-- <a href="https://www.aitimes.com/news/articleView.html?idxno=158799" target="_blank">2024년03월14일 : AI Times 구글, '트랜스포머' 보완할 기술 잇달아 공개…”메모리·시간 축소” </a> <br><br> -->
                    </p>
            
                    </li>
                    <!-- 이곳에 더 많은 표현을 추가할 수 있습니다 -->
                    </ul>

    <style>
        /* Increase the font size on screens smaller than 600px (typical size for mobile phones) */
        @media only screen and (max-width: 600px) {
            body {
                font-size: 3em !important;
            }
        }
        
    </style>

</main>


<footer>
   © 2023~2024 AI NEWS. All rights reserved.
   <a href="mailto:stberry7@gmail.com?subject=Hello&amp;body=Nice%20to%20meet%20you">
    Email me
   </a>
</footer>
<script>
   var clickCount = 0;
  </script>
<style>
.firework {
    position: absolute;
    width: 1px;
    height: 1px;
    border-radius: 50%;
    background: red;
    animation: explode 3s ease-out;
}

@keyframes explode {
    to {
        transform: scale(30);
        opacity: 0;
    }
}
</style>
<script>
var colors = ['#ffb3ba', '#ffdfba', '#ffffba', '#baffc9', '#bae1ff'];

document.addEventListener('click', function(event) {
    if (event.clientX < 30 || event.clientX > window.innerWidth - 30 ||
        event.clientY < 30 || event.clientY > window.innerHeight - 30) {
        return;
    }
    for (var i = 0; i < 10; i++) {
        var firework = document.createElement('div');
        firework.className = 'firework';
        // firework.style.top = (event.clientY - 0.5) + 'px';
        firework.style.top = (event.clientY+ window.scrollY - 0.5) + 'px';
        firework.style.left = (event.clientX - 0.5) + 'px';
        // firework.style.top = (event.clientY + window.scrollY - 0.5) + 'px'; // Adjusted for scroll
        firework.style.backgroundColor = colors[Math.floor(Math.random() * colors.length)];
        firework.style.transform = 'translate(' + (Math.random() * 200 - 100) + 'px, ' + (Math.random() * 200 - 100) + 'px)';
        document.body.appendChild(firework);
        setTimeout(function() {
            document.body.removeChild(firework);
        }, 3000);
    }
});
</script>
</body>
</html>
