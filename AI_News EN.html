<!DOCTYPE html>
<html lang="en">
<head>
    <!-- Google Tag Manager -->
    <script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
    new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
    j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
    'https://www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);
    })(window,document,'script','dataLayer','GTM-P5MQZ5LK');</script>
    <!-- End Google Tag Manager -->
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>Artificial Intelligence News (AI News)</title>
<meta name="description" content="The latest news and developments in Artificial Intelligence (AI) and related fields. Stay up-to-date with the most recent AI breakthroughs, research, and applications.">
<meta name="keywords" content="AI news, artificial intelligence news, AI developments, AI research, AI applications, AI breakthroughs, latest AI news">
<meta name="author" content="AI NEWS">
<link rel="canonical" href="https://your-website.com/ai-news">

<style>
    body {
        font-family: Arial, sans-serif;
    }

    header {
        background-color: #f8f9fa;
        padding: 20px;
        text-align: center;
    }

    main {
        margin: 2rem auto;
        max-width: 1200px;
        padding: 0 1rem;
        background-color: #fff;
        box-shadow: 0 0 10px rgba(0, 0, 0, 0.1);
        border-radius: 5px;
        padding: 2rem;
        font-size: 40px;
    }

    @media screen and (max-width: 768px) {
        main {
            font-size: 36px;
        }
    }

    ul {
        list-style-type: none;
        padding: 0;
    }

    li {
        margin-bottom: 10px;
        padding: 10px;
        border: 1px solid #ddd;
        border-radius: 4px;
    }

    footer {
        background-color: #f8f9fa;
        padding: 20px;
        text-align: center;
        position: center;
        width: 100%;
        bottom: 0;
    }

    .home-button {
        display: inline-block;
        padding: 20px 100px;
        font-size: 64px;
        color: white;
        background-color: blue;
        border: none;
        border-radius: 5px;
        text-decoration: none;
        transition: background-color 0.3s ease;
    }

    .home-button:hover {
        background-color: darkblue;
    }

    .circle {
        position: absolute;
        height: 100px;
        width: 100px;
        border-radius: 50%;
        border: 5px solid;
        animation: circleFadeOut 1s forwards;
    }

    @keyframes circleFadeOut {
        from {transform: scale(0.5); opacity: 1;}
        to {transform: scale(1.5); opacity: 0;}
    }

    .message {
        position: absolute;
        font-size: 20px;
        color: red;
        animation: messageFadeOut 1s forwards;
    }

    @keyframes messageFadeOut {
        from {opacity: 1;}
        to {opacity: 0;}
    }

    .highlight-green {
        background-color: lightgreen;
    }
  
    .highlight-yellow {
        background-color: yellow;
    }
</style>
</head>
<body>
    <header>
        <a class="home-button" href="index.html">Home</a>
        <h1>Artificial Intelligence News</h1>
        <p>Welcome to the Artificial Intelligence News webpage.</p>
    </header>
<main>
    <h2>Artificial Intelligence News</h2>

    <ul>
        <li>
            <p>
                <strong><h2>April 2024 marked remarkable advancements in AI and robotics.</h2></strong>
                <br><br>
                <div class="gif-container">
                    <img src="../../image/ai_news/ai news sub 20240505_02.png" alt="AI and robotics advancements" width="100%">
                </div>
                April 2024 was a month of remarkable advancements in the fields of AI and robotics. First, Boston Dynamics unveiled their new humanoid robot, which garnered significant attention. This robot is an upgraded version of their previous model, Atlas. With 360-degree rotatable joints and smooth movements, this robot demonstrated its ability to perform complex actions naturally, such as climbing stairs and lifting objects.<br><br>
                In Wuhan, China, the autonomous driving pilot city project is in full swing. Recently, the world's first electrically-driven humanoid robot, 'Tangong,' was unveiled, creating a buzz. This robot is reportedly capable of stable autonomous driving on various terrains, including ramps and stairs. Designed to be 4.75 feet tall and weigh 170 pounds with 36 joints, Tangong is equipped with sophisticated visual and auditory systems to interact safely with humans.<br><br>
                China's achievements in the AI field were also notable. In particular, the large language model Ernie bot outperformed OpenAI's GPT-4 in several benchmark evaluations. It surpassed GPT-4 in Chinese natural language processing, creativity, and reasoning abilities, and also demonstrated excellent performance in image generation, producing realistic portrait paintings.<br><br>
                Another Chinese company, UB Tech, developed an intriguing humanoid robot called Walker S. This robot is equipped with the Ernie bot language model and vision system, enabling it to perform tasks such as folding clothes and sorting objects completely autonomously. Its modular design allows for easy replacement of robotic hands according to the task, which is expected to increase its versatility.<br><br>
                In a recent interview, OpenAI CEO Sam Altman discussed the future of artificial intelligence technology. He emphasized that creativity, critical thinking, and the ability to understand others' needs will be the most important skills going forward.<br><br>
                Altman also mentioned the timeline for the advent of AGI, or artificial general intelligence. While predicting that AGI will emerge around the 2030s, he acknowledged the difficulty in specifying an exact time. He expressed the view that even with the realization of AGI, our daily lives will not change significantly.<br><br>
                Meanwhile, Altman assessed his company's GPT-4 as "the dumbest model we will face in the future." This implies that the upcoming version, GPT-5, will be much smarter, which is an encouraging prospect.<br><br>
                Altman argued that as AI technology becomes more advanced, although the development will require enormous costs, it is worth investing in because it can create tremendous value for society. However, he added that it is crucial to responsibly develop and gradually deploy more powerful AI systems while continuously incorporating feedback.<br><br>
                So far, we have looked at the major AI and robotics innovations and trends that took place over the month of April 2024. Amidst the fierce competition between the United States and China, the pace of development in this field is accelerating. Robotics companies like Boston Dynamics and UB Tech are striving to push the technological boundaries of humanoid robots, while leading AI companies such as OpenAI and Baidu are showcasing even more advanced language models and multimodal AI systems based on their unique strengths.<br><br>
                It is noteworthy to see how these technological advancements will bring changes to our daily lives, society, economy, and industries as a whole. While there are positive expectations that AI and robots will expand human capabilities and overcome limitations, there are also concerns about job replacement, privacy infringement, and algorithmic bias.<br><br>
                What is clear is that we need to gather wisdom from all sectors of society and continue constructive discourse to wisely navigate this massive technological transition. Academia, industry, policymakers, and civil society must collaborate to proactively prepare for the changes that AI and robotics will bring, maximize their potential, and minimize any adverse effects. It is time to ponder the strategies to do so. We hope that we can all move wisely toward this new future.<br><br>
                <a href="https://www.youtube.com/watch?v=widHHddVPJY" target="_blank">2024-05-04: April 2024 marked remarkable advancements in AI and robotics.</a>
                <br>
            </p>
        </li>
    </ul>

    <ul>
        <li>
            <p>
                <strong><h2>China achieves 10-fold cost reduction in LiDAR sensors, industry taken aback</h2></strong>
                <br><br>
                <div class="gif-container">
                    <img src="../../image/ai_news/ai news sub 20240505_01.jpg" alt="LiDAR cost reduction in China" width="100%">
                </div>
                Wuhan, Hubei Province, has emerged as the world's largest autonomous driving city. In Wuhan's autonomous driving pilot area, fully driverless 'robotaxis' and 'unmanned buses' that can be ridden for just 0.01 yuan (approximately 0.2 cents) are in operation. Wuhan covers an area 14 times larger than Seoul, and China has transformed it into a massive future technology laboratory. China's pace of autonomous driving commercialization is very rapid. Baidu and others, which started autonomous driving businesses in 2013, recorded 732,000 robotaxi rides in Wuhan last year, surpassing the commercial operation record of Google's autonomous vehicle subsidiary Waymo (approximately 700,000 rides) in 2008.<br><br>
                Wuhan has issued about 2,000 autonomous driving test vehicle license plates to companies such as Baidu and Xiaomi, and has also granted commercial autonomous driving vehicle licenses to two companies, Baidu and Dongfeng Weshang. The annual number of passengers is approaching 900,000. The open roads for autonomous driving in China total 22,000 km, of which 3,378 km are open to autonomous vehicles in Wuhan alone.<br><br>
                China's state-owned enterprise Dongfeng Weshang has succeeded in reducing the price of LiDAR, a key component of autonomous driving, to <mark class="highlight-green">8,000 yuan (approximately 1.5 million won) per unit</mark>. This is a remarkable price drop compared to the <mark class="highlight-green">$80,000 (approximately 110 million won) per unit price of the U.S.-made LiDAR imported in 2015</mark>. LiDAR is called the 'eye of autonomous vehicles' due to its high accuracy, but its high price has been one of the stumbling blocks to the commercialization of autonomous driving. China claims to have solved this problem.<br><br>
                Dongfeng Weshang acts as a 'vanguard' in making China's autonomous driving technology a global standard. Established in 2013, this company develops autonomous driving technology and accumulates data through commercial services. Dongfeng plans to invest a total of 100 billion yuan (approximately 19 trillion won) in R&D by next year to achieve technological independence, with the cumulative R&D investment amount reaching 1 trillion won.<br><br>
                China has transformed the entire city into an autonomous driving laboratory to export the concept of an intelligent city armed with 'City Brain,' an artificial intelligence (AI), and advanced mobility as a model. Autonomous driving requires a total solution that includes not only sensor technology but also vehicle-specific precision maps and navigation, transportation infrastructure design tailored to each city's characteristics, and safety education in order for it to operate without accidents. In Wuhan, citizens are experiencing and accepting the arrival of the autonomous driving era through autonomous bus fares of just 0.01 yuan (approximately 0.2 cents) and safety education from a young age.<br><br>
                China is striving for the commercialization of autonomous driving because this technology is not only a 'game changer' in transportation but also has military applications. Autonomous driving technology is considered the core of the U.S.-China technology hegemony war. China accounted for 30.7% of patents related to Advanced Driver Assistance Systems (ADAS) from 2013 to 2019, surpassing the United States (27.6%) and Japan (20.8%). Most of the components used in autonomous vehicles are also known to be manufactured with China's own technology.<br><br>
                <a href="https://www.hankyung.com/amp/2024050578181" target="_blank">2024-05-05: China achieves 10-fold cost reduction in LiDAR sensors, industry taken aback</a>
                <br>
            </p>
        </li>
    </ul>

    <ul>
        <li>
            <p>
                <strong><h2>Video of humanoid robot showcasing ultra-high speed and precision movements goes viral</h2></strong>
                <br><br>
                <div class="gif-container">
                    <img src="../../image/ai_news/ai news sub 20240428_03/ai news sub 20240428_03_Animdated.gif" alt="Humanoid robot S1 by Astribot" width="100%">
                </div>
                A video of the AI-based humanoid robot S1, recently unveiled by Chinese company Astribot, is capturing the attention of the industry. Although new humanoid robots are being announced every week, few robots move as quickly and precisely as the S1.<br><br>
                According to Astribot, the S1 can execute movements at a speed of up to 10 meters per second and handle a load of 10 kg on each arm. In the released video, the S1 demonstrated impressive speed by pulling a tablecloth from under a pile of wine glasses. However, it not only showcased speed but also delicate and precise movements, such as pouring wine, cutting cucumbers, and flipping sandwiches in a frying pan.<br><br>
                Another feature of the S1 is its excellence in mimicking human movements. This suggests that the S1 is a robot with outstanding learning capabilities. However, the video does not reveal the S1's lower body, raising questions about its actual mobility.<br><br>
                Astribot is a startup established in Shenzhen, China, in 2022, and the development of the S1 took approximately one year, with the goal of commercialization by the end of this year. The parent company, Stardust Intelligence, was founded by Lai Jie, who previously worked at Tencent Robotics Lab.<br><br>
                The company explained that the name Astribot was derived from the Latin proverb "Ad astra per aspera," which means "through hardships to the stars," symbolizing the company's determination to develop and popularize AI robot technology.<br><br>
                The industry expects the competition in the humanoid robot market to intensify with the emergence of the S1. It remains to be seen whether Astribot can establish a foothold in the market based on its technological capabilities. Although detailed specifications and prices of the S1 have not yet been disclosed, if commercialization is successful, it could be a catalyst for the popularization of humanoid robots.<br><br>
                <a href="https://ko.root-nation.com/ua/articles-ua/tech-ua/ua-phi-3-mini/" target="_blank">2024-04-28: Video of humanoid robot showcasing ultra-high speed and precision movements goes viral</a>
                <br>
            </p>
        </li>
    </ul>

    <script>
        const gifContainer = document.querySelector('.gif-container');
        const gifImage = gifContainer.querySelector('img');
      
        gifContainer.addEventListener('click', () => {
            if (gifImage.style.animationPlayState === 'paused') {
                gifImage.style.animationPlayState = 'running';
            } else {
                gifImage.style.animationPlayState = 'paused';
            }
        });
    </script>

    <style>
  .gif-container {
    display: inline-block;
    cursor: pointer;
  }
</style>
</style>
    <ul>
        <li>
            <p>
                <strong><h2>Microsoft unveils new small language model 'Phi-3' with improved performance without fine-tuning</h2></strong>
                <br><br>
                <img src="../../image/ai_news/ai news sub 20240428_02.png" alt="Microsoft Phi-3 small language model" width="100%">           
                Microsoft has announced a new small language model (SLM) called 'Phi-3' that outperforms similar-sized and next-sized models in various benchmarks evaluating language, coding, and math abilities, thanks to learning innovations developed by Microsoft researchers. This is the first publicly available model in the Phi-3 family, which is the most capable and cost-effective SLM to date.<br><br>
                Microsoft has revealed Phi-3-mini, which measures 3.8 billion parameters and outperforms models twice its size, as the first of a more powerful SLM family. Starting today, Phi-3-mini is available in the Microsoft Azure AI model catalog, the machine learning model platform Hugging Face, and the lightweight framework Ollama for running models on local machines. It will also be offered as an NVIDIA NIM microservice with a standard API interface that can be deployed anywhere.<br><br>
                Microsoft has also announced that additional models will soon be released in the Phi-3 family to provide more options in terms of quality and cost. Phi-3-small (7 billion parameters) and Phi-3-medium (14 billion parameters) will soon be available in the Azure AI model catalog and other model gardens.<br><br>
                Small language models are designed to perform well on simpler tasks, are more accessible and easier to use for organizations with limited resources, and are more amenable to fine-tuning for specific requirements.<br><br>
                Sonali Yadav, a senior product manager for generative AI at Microsoft, said, "What we're going to see going forward is not a shift from large to small, but a shift from a single category of models to a portfolio of models where customers can determine the model that's best suited for their scenario."<br><br>
                Luis Vargas, Microsoft's vice president of AI, said, "Some customers may only need small models, some will need large models, and many customers will want to combine the two in different ways."<br><br>
                Choosing the right language model depends on an organization's specific needs, the complexity of the task, and available resources. Small language models are suitable for organizations looking to build applications that can run locally on devices without the cloud and for tasks that do not require extensive inference or need quick responses.<br><br>
                Small language models also offer potential solutions for regulated industries and domains that face situations where high-quality results are needed but prefer to keep data in-house, Yadav said.<br><br>
                Vargas and Yadav are particularly excited about the opportunity to deploy more capable SLMs on smartphones and other mobile devices that operate "at the edge," unconnected to the cloud. (Think automobile computers, PCs without Wi-Fi, smart sensors on factory floors, remote cameras, or devices monitoring environmental regulatory compliance.) By keeping data on-device, users can "minimize latency and maximize privacy," Vargas said.<br><br>
                Latency refers to the lag that can occur when an LLM communicates with the cloud to retrieve the information used to generate a response to a user prompt. In some cases, it's worth waiting for a high-quality answer, but in other scenarios, speed is more important to user satisfaction.<br><br>
                Because SLMs can operate offline, more people will be able to harness AI in ways that were previously impossible, Vargas said.<br><br>
                For example, an SLM could be used in rural areas where cellular service is lacking. Consider a farmer inspecting crops who discovers signs of disease on leaves or branches. Using an SLM with visual capabilities, the farmer could take a picture of the problem crop and receive immediate recommendations on how to treat the pest or disease.<br><br>
                "If you're in parts of the world without good networks, you'll still be able to have AI experiences on device," Vargas said.<br><br>
                The role of high-quality data<br><br>
                As the name suggests, SLMs are much smaller than LLMs. At least by AI standards. Phi-3-mini has "only" 3.8 billion parameters, a unit of measurement that represents the algorithmic knobs that help determine a model's output. In contrast, the largest large language models are much larger in size.<br><br>
                The tremendous advancements in generative AI made by large language models have been largely attributed to their sheer size. However, the Microsoft team was able to develop small language models that deliver tremendous results in a small package. This breakthrough was made possible through a highly selective approach to training data, which is where the storybooks come into play.<br><br>
                Until now, the standard method of training large language models has been to use massive amounts of data from the internet. This was considered the only way to satisfy these types of models' enormous appetite for content needed to understand the nuances of language and generate intelligent responses to user prompts. However, Microsoft researchers had a different idea.<br><br>
                Sébastien Bubeck, Microsoft's vice president of generative AI research who has led the development of more capable small language models, asked, "What if, instead of just training on raw web data, we look for extremely high-quality data?" But where to focus?<br><br>
                Inspired by Eldan's nightly reading ritual with his daughter, Microsoft researchers decided to create an individual dataset starting with 3,000 words, including roughly equal numbers of nouns, verbs, and adjectives. They then asked a large language model to create a children's story using one noun, one verb, and one adjective from the list, which was repeated hundreds of millions of times over several days, generating millions of small children's stories.<br><br>
                SLMs are ... uniquely positioned for computation that doesn't need to go to the cloud to complete a task.<br><br>
                The researchers named the resulting dataset "TinyStories" and used it to train a very small language model with about 10 million parameters. Surprisingly, when asked to create its own stories, the small language model trained on TinyStories generated fluent narratives with perfect grammar.<br><br>
                Next, they took the experiment a step further. This time, a larger group of researchers trained Phi-1 using carefully selected public data filtered based on educational value and content quality. After collecting the initial dataset from publicly available information, they used a prompting and seeding formula similar to the one used for TinyStories, but took it a step further and made it more sophisticated to capture a broader range of data. <br><br>
                To ensure high quality, the resulting content was repeatedly filtered and fed back to the LLM for additional synthesis. In this way, they built a data corpus large enough to train a more capable SLM over the course of a few weeks.<br><br>
                The researchers named this dataset "CodeTextbook."<br><br>
                The researchers further enhanced the dataset by approaching data selection like a teacher breaking down difficult concepts for a student. "Because you're reading materials like textbooks, very well-explained, high-quality documents, it makes the job of the language model reading and understanding this material much easier," Bubeck said.<br><br>
                Distinguishing between high-quality and low-quality information is not difficult for humans, but examining over 1 terabyte of data that Microsoft researchers decided was necessary to train the SLM would be impossible without the help of an LLM.<br><br>
                Ece Kamar, a vice president who leads Microsoft Research's AI Frontiers lab, where the new learning approach was developed, said, "The power of the current generation of large language models is a real driving force that we didn't have before in terms of synthetic data generation."<br><br>
                Starting with carefully selected data can reduce the likelihood of the model returning unwanted or inappropriate responses, but it is not sufficient to prevent all potential safety issues. Like with the launch of any generative AI model, Microsoft's product and responsible AI teams used a multi-layered approach to manage and mitigate risks in the development of the Phi-3 models.<br><br>
                For example, after initial training, they provided additional examples and feedback on how the model should ideally respond, which helps build an additional safety layer and assists the model in generating high-quality results. Each model also goes through evaluation, testing, and manual red-teaming, a process where experts identify and address potential vulnerabilities.<br><br>
                Finally, developers using the Phi-3 model family will also have access to a set of tools available in Azure AI to help them build safer and more trustworthy applications.<br><br>
                Choosing the right size language model for the appropriate task<br><br>
                However, there are limitations to small language models trained on high-quality data. They are not designed for the excellent deep knowledge retrieval that LLMs are capable of due to their larger capacity and training on much larger datasets.<br><br>
                LLMs are superior to SLMs in complex reasoning on vast amounts of information due to their size and processing power. This can be relevant for tasks such as sifting through extensive scientific papers, analyzing complex patterns, and understanding interactions between genes, proteins, or chemicals, which could be related to new drug development.<br><br>
                Vargas said, "Tasks that are complex enough that you have to figure out how to break that task down into multiple subtasks, sometimes sub-subtasks, and then have a plan to execute all of these tasks to present a final answer, that's going to be in the realm of large models for a while."<br><br>
                Based on ongoing conversations with customers, Vargas and Yadav expect some businesses to "offload" certain tasks to smaller models when the tasks are not too complex.<br><br>
                For example, a company could use Phi-3 to summarize the main points of a long document or extract relevant insights and industry trends from market research reports. Other organizations might use Phi-3 to help generate content for marketing or sales teams, such as product descriptions or social media posts. Or a business could use Phi-3 to power a support chatbot that answers customers' basic questions about plans or service upgrades.<br><br>
                Internally, Microsoft is already using a suite of models where large language models act as a router, passing specific queries that require less computing power to small language models while handling other more complex requests themselves.<br><br>
                "The argument here is not that SLMs will replace or supersede large language models," Kamar said. Instead, SLMs are "uniquely positioned for computation at the edge, computation on device, computation that doesn't need to go to the cloud to complete a task. And that's why it's important for us to understand the trade-offs of this portfolio of models," she explained.<br><br>
                And size has significant advantages. There is still a gap between the level of intelligence that can be obtained from small language models and large models in the cloud, Bubeck said. "And maybe there will always be a gap. Because large models will also continue to make progress."<br><br>
                <a href="https://news.microsoft.com/source/features/ai/the-phi-3-small-language-models-with-big-potential/" target="_blank">2024-04-25: MICROSOFT Tiny but mighty: The Phi-3 small language models with big potential</a>
                <br>  
            </p>
        </li>
    </ul>

    <ul>
        <li>
            <p>
                <strong><h3>RAG completes the missing piece in generative AI</h3></strong>
                <br><br>
                The process of implementing generative AI in enterprises has been a series of trial and error since its emergence, which has garnered worldwide attention. While the use of AI chatbots in daily tasks has led to a surge in shadow AI usage within companies, generative AI has yet to fulfill its grand promise of revolutionizing work processes in knowledge-intensive workflows.<br><br>
                <img src="../../image/ai_news/RAG1.jpg" alt="Retrieval-Augmented Generation (RAG)" width="100%">
                However, this period of disillusionment is not expected to last long, thanks to a process called Retrieval-Augmented Generation (RAG). RAG is enabling previously impossible use cases for generative AI within enterprises, and OpenAI, Microsoft, Meta, Google, Amazon, and many AI startups are aggressively launching enterprise-centric RAG-based solutions.<br><br>
                RAG addresses a major problem that has been hindering the adoption of generative AI in enterprises: the information retrieval model. Generative AI tools can now access and generate results based on relevant data outside the data learned by large language models (LLMs). Although it sounds simple, this is a key feature for unleashing the potential of generative AI tools in enterprise use cases.<br><br>
                When generative AI cannot access information outside the training data, problems arise. Generative AI tools like ChatGPT are based on LLMs, which are trained on a limited scope of data collected at a specific point in time, lacking domain-specific or up-to-date data. Moreover, LLMs have a hallucination problem, where they generate facts that appear credible based on learned language patterns, posing a stumbling block in enterprise workflows where accuracy is crucial.<br><br>
                Enterprises require generative AI that is first, comprehensive and timely, including all relevant up-to-date domain-specific data; second, trustworthy and transparent, citing all sources used in the results; and third, accurate, based on reliable specific datasets rather than LLM training data.<br><br>
                RAG can meet these requirements. RAG-based systems integrate search-based models and generative models to handle knowledge-intensive workflows that extract accurate summaries and insights from large volumes of incomplete unstructured data and present them clearly and accurately in natural language.<br><br>
                The four stages of RAG are as follows: first, vectorization, which converts relevant text information from reliable sources into special codes that the system can use for classification; second, search, which uses mathematical representations to match queries with similar codes contained in trusted information sources; third, ranking, which selects the most useful information considering the question content, user, and information source; and fourth, the generation stage, which supplies the most relevant parts of the document combined with the question to the LLM to generate the result.<br><br>
                As long as the underlying data is properly sourced and validated, RAG-based generative AI tools can generate results that are far more accurate, comprehensive, and relevant than tools that rely solely on LLMs. Enterprise users will also be able to trust and utilize the outputted results in important workflows.<br><br>
                Accordingly, OpenAI has begun introducing RAG capabilities to ChatGPT, and the latest search tools like Perplexity AI are gaining popularity with responses that cite original sources. However, more time and investment are still needed to tailor it to domain-specific enterprise use cases.<br><br>
                Preparing for enterprise use means sourcing and curating domain-specific underlying data, customizing searches, ranking searches to return the most relevant documents for the use case, and fine-tuning the LLM to use the correct terminology, tone, and format in the output.<br><br>
                Despite the initial excitement surrounding generative AI, actual adoption in enterprises has been low so far. However, RAG is changing the game by providing generative AI solutions in areas that demand accuracy, reliability, and domain specificity. The emergence of RAG is opening up new opportunities for realizing generative AI in enterprises.<br><br>
                <a href="https://www.itworld.co.kr/news/334800" target="_blank">2024-04-25: ITWORLD The missing piece in generative AI, completed by RAG</a>
                <br>  
            </p>
        </li>
    </ul>

    <ul>
        <li>
            <p>
                <strong><h3>Tencent's AI learns 3 trillion tokens, faster learning speed than ChatGPT</h3></strong>
                <br><br>
                It has been revealed that the number of tokens (corpus) recently learned by 'Hunyuan,' the large language model (LLM) developed by Tencent, China's largest information technology (IT) company, has reached 3 trillion. This is a 50% increase from the 2 trillion announced just 7 months ago when Hunyuan was first unveiled in September last year. This is an overwhelming scale compared to the 560 billion tokens of Naver's HyperCLOVA, the first Korean LLM introduced in 2021, and a much faster pace than the 300 billion tokens invested by Sam Altman's OpenAI, known as the 'father of ChatGPT,' when GPT3 was launched in 2020. This is why global big tech companies are wary of Tencent's rapid pursuit.<br><br>
                Tencent's full-fledged involvement in AI development dates back to 2016. At that time, Tencent established the Tencent AI Lab and began utilizing the vast amount of data accumulated through its social networking services, WeChat and Weixin CopyClaude does not have the ability to run the code it generates yet.J계속, for AI training. According to the WeChat and Weixin office in Guangzhou, China, visited on the 18th, the current number of users of these two SNS services reaches 1.447 billion. Among them, 1.359 billion are Chinese users, meaning almost all Chinese people use them, and foreign users also approach 100 million. A Tencent official said, "While most AI companies are struggling with a lack of data for tokens, Tencent does not have to worry." This is because WeChat serves as a 'life remote control' used in all aspects of daily life, from financial transactions to medical appointments, prescription delivery, restaurant payments, taxi calls, and shared bicycle use, allowing Tencent to secure a large volume of tokens necessary for AI training.<br><br>
Tokens are considered the most definitive means for improving AI performance. No matter how state-of-the-art AI chips are used, if there is a lack of data input for training, there is a limit to performance improvement. On the other hand, even if the chip's performance is somewhat inferior, better results can be expected if vast amounts of data are trained. A Naver official said, "The only ones securing large-scale real-time data offline are Chinese big tech companies."<br><br>
Tencent's chairman, Pony Ma, is advancing Hunyuan while expanding the business area into enterprise AI. In a recent message sent to employees, he emphasized, "Hunyuan is a top-tier model that demonstrates excellent performance in numerical inference, logical inference, and multi-step conversation." Hunyuan supports various functions such as image generation, text recognition, and copywriting, and has high utilization in major industries such as SNS, finance, public services, e-commerce, logistics transportation, and gaming. Dowson Tong, Tencent's senior vice president, said, "We are providing enterprise Hunyuan services with over 50 solutions across 20 industries, including finance, education, logistics, and gaming, to Chinese companies," and added, "We will introduce intelligent services optimized for each company."<br><br>
Enterprise AI has been considered China's biggest weakness. Unlike the consumer sector, Chinese companies lacked 'structured data' that they had accumulated on their own. Tencent plans to overcome this weakness by gathering data from major industries through its AI cloud. Chairman Pony Ma's strategy is to create a separate 'AI planet' that is completely different from the super-large AI ecosystem led by Google, Amazon, and Microsoft. In fact, Tencent demonstrated its will by unveiling its self-developed generative AI game engine 'Gninex' last month. It is an innovative tool that can shorten content production time and create rich game stories using generative AI. Tencent is currently applying Hunyuan's enterprise AI to its own businesses and services, which number around 400.<br><br>
Tencent is also actively working on global market penetration based on AI technology. Starting with the establishment of a global partner network spanning Asia, Europe, and the United States in 2016, it has accelerated its overseas expansion, and recently, it is building its own ecosystem in Latin America and the Middle East. Zhao Jiennan, vice president of Tencent Cloud International, said, "We will grow our global business in the form of building customized digital solutions by integrating key technologies such as cloud, AI, big data, and security." To this end, Tencent invested 64 billion yuan (approximately 12 trillion won) in research and development (R&D) last year alone, which is the largest ever. It is known that the proportion of AI-related investments in R&D will be further increased this year.<br><br>
This is why the ambitious move of China's IT giant Tencent is drawing attention. The strategy is to showcase its presence on the global stage using data accumulated based on its dominant position in the domestic market and AI technological prowess. It remains to be seen whether it can emerge as a new powerhouse in the AI market led by U.S. big tech companies such as Google, Amazon, and Microsoft. However, issues such as Chinese government regulations and censorship, as well as data security concerns, still remain as challenges that Tencent must overcome. Meeting universal values and standards that can be accepted in the global market is also an important task. It remains to be seen whether Tencent's move will demonstrate new possibilities for Chinese IT companies or expose limitations confined to the domestic market.<br><br>
<a href="https://www.hankyung.com/article/2024042159721" target="_blank">2024-04-21: Hankyung - Tencent's AI learns 3 trillion tokens, faster learning speed than ChatGPT</a>
<br>
</p>
</li>
</ul>
    <ul>
        <li>
            <p>
                <strong><h3>"The days of billion-dollar salaries are over"... AI takes over the work of 4 employees, 'large-scale layoffs'</h3></strong>
                <br><br>
                As artificial intelligence (AI) has become capable of performing coding, the core task of IT developers, at an intermediate level or higher, companies are shifting their investment from high-paid IT developers to cost-effective AI. As a result, the position of IT developers is being shaken.<br><br>
                Recently, global companies are investing in their own AI development with the funds they would have used to recruit IT talent. Overseas big tech companies such as Google, Microsoft, and Amazon are carrying out large-scale restructuring and investing the reduced costs in AI development. Google plans to invest $37 billion (approximately 51 trillion won), Microsoft £2.5 billion (approximately 4 trillion won), and Amazon $4 billion (approximately 5 trillion won) and $100 million (approximately 138.5 billion won) in AI-related fields, respectively.<br><br>
                Experts predict that AI will soon be able to replace the jobs of IT developers. NVIDIA CEO Jensen Huang mentioned that the advancement of AI could lead to the disappearance of coding-specific occupations, and Professor Kim Myung-joo of Seoul Women's University explained that applying AI to coding can improve efficiency by 30-40%. Ark Invest estimated that AI can increase coding productivity by tenfold.<br><br>
                In Korea, concerns about AI replacing IT developer jobs are also spreading. According to a survey by Wanted Lab, 83.6% of respondents answered that AI would replace developer tasks. In fact, IT developer recruitment in Korea is showing a decreasing trend, and according to an analysis by Saramin, job postings for IT development and data positions decreased by 7.4% last year compared to the previous year.<br><br>
                Large Korean IT companies are also lowering the rate of salary and incentive increases and focusing their investments on AI. Naver and Kakao's average employee salaries decreased by 11.5% and 27.3%, respectively, which seems to be a measure to increase investment in AI.<br><br>
                Experts predict that if companies confirm the efficiency of AI, they are likely to reduce new developer hiring, except for outstanding talent. The advancement of AI is expected to have a significant impact on IT developer jobs, and changes in the employment structure are anticipated accordingly.<br><br>
                In the IT industry, there is a trend of avoiding the recruitment of entry-level developers and selecting verified experienced personnel. Companies are reducing their recruitment scale by operating only project-based occasional recruitment.<br><br>
                Due to the advancement of AI and changes in companies' investment strategies, the employment environment for IT developers is rapidly changing. Simple coding tasks are being replaced by AI, and developers are expected to transition to roles that utilize and manage AI. To respond to these changes, developers need to strengthen their competencies, and employment stability measures at the corporate and government levels are deemed necessary.<br><br>
                <a href="https://m.mk.co.kr/amp/10992831" target="_blank">2024-04-17: Maeil Business Newspaper - "The days of billion-dollar salaries are over"... AI takes over the work of 4 employees, 'large-scale layoffs'</a>
                <br>  
            </p>
        </li>
    </ul>

    <ul>
        <li>
            <p>
                <strong><h3>The 20 most used AI platforms in 2024 are...</h3></strong>
                <br><br>
                The ranking of the most used artificial intelligence (AI) platforms in 2024 has been announced. The American investment specialized media, Insider Monkey, selected platforms that appeared in more than 50% of over 10 ranking sites on the internet and ranked them based on the total number of site visits over the past 28 days. For platforms without websites, the total number of subscribers or users was used as the criteria.<br><br>
                OpenAI's ChatGPT took first place. It recorded an overwhelming performance with 1.61 billion visits. Google's Gemini took second place with 391.2 million visits, and surprisingly, the translation AI DeepL came in third with 241.3 million visits.<br><br>
                From 4th to 10th place, Character.AI's chatbot, Perplexity AI's AI-based search engine, Anthropic's Claude, Quora's AI chatbot Poe, Microsoft's Copilot, the AI language model DialoGPT, and the AI-based search engine YouChat took their respective positions.<br><br>
                Among the top 10, DeepL was the only platform that was not based on large language models (LLMs) or AI chatbots. Microsoft's ranking at 8th place was an unexpected result, and the rise of AI-based search engines like Perplexity AI and YouChat was also noteworthy.<br><br>
                From 11th to 20th place, Otter, an AI-based meeting assistant, Socratic, a homework helper for students, Helix.AI, a writing support AI, Writesonic, Copy.AI, the AI chatbot Jasper, the English voice assistant Elsa, GitHub's coding assistant Copilot, Kodium, and Tab 9 took their respective positions.<br><br>
                This ranking well illustrates the popularity and usage status of AI platforms. While the explosive popularity of conversational AI models like ChatGPT stands out, it shows that AI technology is being applied in various fields such as translation, search, meetings, learning, writing, and coding.<br><br>
                In particular, not only AI platforms from large IT companies but also startups and specialized AI services are ranked high, reflecting the diversity and competitive landscape of the AI industry. The rise of new AI search engines like Perplexity AI and YouChat is also noteworthy.<br><br>
                As the advancement and popularization of AI technology accelerate, these AI platforms are expected to have an increasing impact on our daily lives and work methods. At the same time, discussions on AI ethics, privacy, and jobs will become more important.<br><br>
                The 2024 AI platform ranking provides an interesting snapshot of the rapidly changing AI technology ecosystem while suggesting the direction of future developments. It can be an opportunity to think about the changes and opportunities that AI technology will bring and the tasks our society needs to prepare for.<br><br>
                <a href="https://www.aitimes.com/news/articleView.html?idxno=158780" target="_blank">2024-04-14: AI Times - The 20 most used AI platforms in 2024 are...</a>
                <br>
            </p>
        </li>
    </ul>

    <ul>
        <li>
            <p>
                <strong><h3>"GPT-4 has become lazy again... Let's switch to Claude 3" - Public opinion spreads</h3></strong>
                <br><br>
                As the 'laziness' problem resurfaces in OpenAI's chatbot GPT-4, there is a growing opinion among users to switch to Anthropic's competing model, 'Claude 3'.
                The laziness problem in GPT-4 refers to the phenomenon where the chatbot refuses to respond or does not function properly. This issue first emerged last summer and was considered a temporary performance degradation due to the application of the 'Mixture of Experts (MoE)' model splitting process at the time. However, as the problem recurred, OpenAI attempted to resolve it by releasing GPT-4 Turbo last November.<br><br>
                Similar issues occurred again earlier this year, and although OpenAI CEO Sam Altman acknowledged and corrected them through Twitter, the problem has recently resurfaced. Users are expressing their dissatisfaction with the model's performance degradation and incomplete code generation through developer forums and SNS.<br><br>
                In the past, users had to endure this, but now there is an alternative in the form of Anthropic's 'Claude 3'. Claude 3 is demonstrating performance surpassing GPT-4 in benchmark results and human preference evaluations. Angel investor Ellie Miller mentioned that most people are using Claude 3, and Wharton School professor Ethan Mollick emphasized the superiority of Claude 3 by citing specific examples.<br><br>
                There are also doubts about whether OpenAI can adequately address this issue. Miller predicted that OpenAI would not invest sufficient resources to solve this problem as they are focusing on developing the next model. In fact, recent reports suggest that OpenAI plans to release GPT-5 this summer.<br><br>
                This incident highlights the intensifying competition in the AI chatbot market. If the laziness problem in GPT-4 persists, user churn may accelerate, and the market share of competing models like Claude 3 could expand. There are concerns that OpenAI's market position may be shaken if they do not resolve this issue promptly and effectively.<br><br>
                Meanwhile, this case illustrates the various technical and social issues that can arise in the development and commercialization of AI technology. The performance and stability of chatbots, user experience, and companies' response capabilities are emerging as important topics, and these factors are expected to influence the development direction and speed of the AI industry. As competition and innovation in AI technology accelerate, providing services that meet users' demands and expectations is becoming a key challenge for companies.<br><br>
                <a href="https://www.aitimes.com/news/articleView.html?idxno=158387" target="_blank">2024-03-29: AI Times - "GPT-4 has become lazy again... Let's switch to Claude 3" - Public opinion spreads</a>
                <br>
            </p>
        </li>
    </ul>

    <ul>
        <li>
            <p>
                <strong><h3>Technologies to complement 'Transformer' unveiled one after another... "Memory and time reduction"</h3></strong>
                <br><br>
                Google has unveiled a series of new technologies to address the shortcomings of the 'Transformer' architecture, which slows down inference speed and requires a large memory space as input data grows. This shows that attempts to surpass the 'Attention Mechanism' are being made in earnest 7 years after its announcement.<br><br>
                First, Google published a paper on the 'Infini-attention' technology, which can infinitely expand the context window length of large language models (LLMs), on an online archive. The Transformer architecture used in LLMs such as 'ChatGPT' and 'Gemini' has the disadvantage that the required memory and computation time increase exponentially as the context window grows. For example, if the input size is expanded from 1000 tokens to 2000 tokens, the memory and computation time required to process the input increase by four times, not two times. This is due to the 'Attention Mechanism' that processes input information in parallel to reveal the correlation between tokens in the text.<br><br>
                To solve this problem, Google introduced the Infini-attention technology, which allows LLMs to process text of infinite length while keeping memory and computing requirements constant. Infini-attention integrates 'compressed memory' into the general attention mechanism, so when the input exceeds the context length, the model stores the previous attention state in the compressed memory for computational efficiency. To maintain the entire context history, the previous context's attention state is not discarded but stored in the compressed memory when processing the next context length.<br><br>
                According to Google, an LLM with Infini-attention can maintain the quality of over 1 million tokens without additional memory. The research team explained that by making subtle but important modifications to the attention mechanism of the Transformer architecture, existing LLMs can be naturally extended to infinitely long contexts. They also claimed that Infini-attention outperformed other long-context Transformer-based LLMs in the Perplexity benchmark, which measures a model's consistency over very long contexts, while using 114 times less memory.<br><br>
                Using an LLM that supports infinite context length, theoretically, all documents can be inserted into the prompt, and the model can be made to select the most relevant answer for each query. Also, instead of fine-tuning the model to improve performance for a specific task, long examples can be provided to customize the model without the need for fine-tuning.<br><br>
                Furthermore, Google published a paper on 'RecurrentGemma,' an open-source small language model (sLM) for edge devices, on an online archive. This model also compl CopyClaude does not have the ability to run the code it generates yet.J계속ements the attention mechanism of the Transformer architecture and maintains performance equivalent to LLMs while significantly reducing memory and processing requirements.<br><br>
Transformers have a weakness in that memory and processing requirements increase significantly with increasing data volume due to the attention mechanism that processes all input data in parallel. As a result, LLMs are difficult to deploy on resource-constrained devices such as smartphones, Internet of Things (IoT), and personal computers, and they are not suitable for AI applications that require real-time responses because they run on remote servers in data centers.<br><br>
On the other hand, RecurrentGemma introduced a 'local attention mechanism' that focuses on processing input data at a given time instead of processing all information in parallel like Transformer-based models. This reduces computational load and increases processing speed without significantly degrading performance. It is suitable for deployment on resource-constrained edge devices and does not need to be executed on remote servers, making it suitable for real-time edge applications.<br><br>
RecurrentGemma combines linear recurrence, a basic component of recurrent neural networks (RNNs) that sequentially remembers previous information by maintaining a 'hidden state' that is updated when new input data is processed, with attention. This allows it to process extended text while maintaining a constant level of resource usage regardless of the input data. In particular, RecurrentGemma minimizes the need for GPUs to continuously reprocess large amounts of data by reducing the processing range.<br><br>
As hardware requirements are reduced, models like RecurrentGemma are more suitable for edge computing applications that typically have less computing power than servers designed for ultra-large clouds. This enables language models to be run directly on edge devices such as smartphones, IoT devices, or embedded systems without relying on cloud connectivity.<br><br>
Infini-attention and RecurrentGemma, unveiled by Google, are expected to contribute to overcoming the limitations of the Transformer architecture and expanding the scope of LLM utilization. Infini-attention can process contexts of infinite length, broadening the application areas of LLMs, and RecurrentGemma provides a small model that can operate in real-time on edge devices, contributing to the popularization of AI technology.<br><br>
These technological innovations demonstrate how fierce the competition is in the AI field and suggest that various attempts are being made to overcome the limitations of the Transformer architecture. New ideas and approaches are expected to emerge for the advancement of AI technology, further expanding the performance and scope of AI technology.<br><br>
<a href="https://www.aitimes.com/news/articleView.html?idxno=158799" target="_blank">2024-03-14: AI Times - Google unveils technologies to complement 'Transformer' one after another... "Memory and time reduction"</a>
<br><br>
</p>
</li>
</ul>
    <ul>
        <li>
            <p>
                <strong><h3>Generative AI released that creates webtoons when news stories are inputted</h3></strong>
                <br>
                American startup Lore Machine has launched an artificial intelligence (AI) tool that generates webtoons or graphic novels in various styles when a lengthy story is inputted, along with images, sounds, and animations tailored to the story.<br><br>
                <img src="../../image/ai_news/ai news sub 20240306_01 lore machine.png" alt="Lore Machine AI tool" width="100%">
                Lore Machine particularly highlighted 'consistency maintenance' as the biggest advantage of this tool.<br><br>
                Reuters, MIT Tech Review, and others reported on the 5th (local time) that Lore Machine unveiled an AI visual storytelling platform and introduced monthly plans ranging from $10 to $160 (approximately 13,400 won to 213,800 won), and is currently in the process of attracting investments.<br><br>
                This tool can create webtoons and other content by generating consistent images when a text prompt with up to 30,000 words, such as a short story or script, is inputted. For $10 per month, users can upload 100,000 words and create 80 images, while the most expensive $160 plan generates 1,792 images with 2.24 million words.<br><br>
                The generated images can be customized into various styles, from North American cartoons to Japanese manga, watercolors, and live-action. Users complete their work by selecting and generating scenes according to the storyboard. Some user reviews mention that it took less than ten clicks to create a comic book using this tool.<br><br>
                Toby Champion, the founder of Lore Machine, received a short film script from Jack Ryder, the founder of the creative agency Modern Arts, and created a 16-page graphic novel overnight.<br><br>
                After reviewing this, the founder of Modern Arts expressed satisfaction, saying, "Image generation itself is not the key. What's important is that everything from the narrative to the emotional depiction of characters fits perfectly with the storytelling." Modern Arts is reportedly currently developing a comic series of the popular Netflix animation 'Love, Death + Robots' using this tool.<br><br>
                The development of Lore Machine originated from founder Champion's experience of creating comic books using Midjourney. While the image quality was excellent, he discovered the problem of difficulty in maintaining consistency between images. For example, the protagonist's hairstyle would become inconsistent, or it was nearly impossible to fix a specific style.<br><br>
                Accordingly, the biggest advantage of the tool developed by Lore Machine lies in maintaining consistency. It utilizes Stable Diffusion for image generation and also incorporates its own language model. The development took one year. While violent or hateful image generation is blocked, it is difficult to 100% prevent hallucinations like other AI tools.<br><br>
                Lore Machine revealed that it has been generating significant revenue since the last quarter, such as being used in the production of advertisements for Chinese computer companies. It is currently discussing partnerships with 20 software platforms and content companies and is also developing a platform version that allows companies to train models in their own style. In the future, it plans to increase the word input limit to 500,000.<br><br>
                Lore Machine reported that it is receiving many requests for educational use in addition to commercial utilization. It is currently in the process of attracting investments, but did not disclose specific details.<br><br>
                <a href="https://www.aitimes.com/news/articleView.html?idxno=157726" target="_blank">AI Times - Generative AI released that creates webtoons when news stories are inputted</a>
                <br>
            </p>
        </li>
    </ul>
    
    <style>
        @media only screen and (max-width: 600px) {
            body {
                font-size: 3em !important;
            }
        }
    </style>
</main>

<footer>
    © 2023~2024 AI NEWS. All rights reserved.
    <a href="mailto:stberry7@gmail.com?subject=Hello&amp;body=Nice%20to%20meet%20you">Email me</a>
</footer>

<script>
    var clickCount = 0;
</script>

<style>
    .firework {
        position: absolute;
        width: 1px;
        height: 1px;
        border-radius: 50%;
        background: red;
        animation: explode 3s ease-out;
    }

    @keyframes explode {
        to {
            transform: scale(30);
            opacity: 0;
        }
    }
</style>

<script>
    var colors = ['#ffb3ba', '#ffdfba', '#ffffba', '#baffc9', '#bae1ff'];

    document.addEventListener('click', function(event) {
        if (event.clientX < 30 || event.clientX > window.innerWidth - 30 ||
            event.clientY < 30 || event.clientY > window.innerHeight - 30) {
            return;
        }
        for (var i = 0; i < 10; i++) {
            var firework = document.createElement('div');
            firework.className = 'firework';
            firework.style.top = (event.clientY+ window.scrollY - 0.5) + 'px';
            firework.style.left = (event.clientX - 0.5) + 'px';
            firework.style.backgroundColor = colors[Math.floor(Math.random() * colors.length)];
            firework.style.transform = 'translate(' + (Math.random() * 200 - 100) + 'px, ' + (Math.random() * 200 - 100) + 'px)';
            document.body.appendChild(firework);
            setTimeout(function() {
                document.body.removeChild(firework);
            }, 3000);
        }
    });
</script>
</body>
</html>